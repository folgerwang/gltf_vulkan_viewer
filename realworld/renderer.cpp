#include <iostream>
#include <stdexcept>
#include <set>
#include <algorithm>
#include <array>

#include "renderer.h"

namespace work {

namespace {
static uint32_t max_vertex_input_attribute_offset = 0;

VkFormat toVkFormat(work::renderer::Format format) {
    auto flag = format;
    SELECT_FLAG(Format, FORMAT, R4G4_UNORM_PACK8);
    SELECT_FLAG(Format, FORMAT, R4G4B4A4_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, B4G4R4A4_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, R5G6B5_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, B5G6R5_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, R5G5B5A1_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, B5G5R5A1_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, A1R5G5B5_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, R8_UNORM);
    SELECT_FLAG(Format, FORMAT, R8_SNORM);
    SELECT_FLAG(Format, FORMAT, R8_USCALED);
    SELECT_FLAG(Format, FORMAT, R8_SSCALED);
    SELECT_FLAG(Format, FORMAT, R8_UINT);
    SELECT_FLAG(Format, FORMAT, R8_SINT);
    SELECT_FLAG(Format, FORMAT, R8_SRGB);
    SELECT_FLAG(Format, FORMAT, R8G8_UNORM);
    SELECT_FLAG(Format, FORMAT, R8G8_SNORM);
    SELECT_FLAG(Format, FORMAT, R8G8_USCALED);
    SELECT_FLAG(Format, FORMAT, R8G8_SSCALED);
    SELECT_FLAG(Format, FORMAT, R8G8_UINT);
    SELECT_FLAG(Format, FORMAT, R8G8_SINT);
    SELECT_FLAG(Format, FORMAT, R8G8_SRGB);
    SELECT_FLAG(Format, FORMAT, R8G8B8_UNORM);
    SELECT_FLAG(Format, FORMAT, R8G8B8_SNORM);
    SELECT_FLAG(Format, FORMAT, R8G8B8_USCALED);
    SELECT_FLAG(Format, FORMAT, R8G8B8_SSCALED);
    SELECT_FLAG(Format, FORMAT, R8G8B8_UINT);
    SELECT_FLAG(Format, FORMAT, R8G8B8_SINT);
    SELECT_FLAG(Format, FORMAT, R8G8B8_SRGB);
    SELECT_FLAG(Format, FORMAT, B8G8R8_UNORM);
    SELECT_FLAG(Format, FORMAT, B8G8R8_SNORM);
    SELECT_FLAG(Format, FORMAT, B8G8R8_USCALED);
    SELECT_FLAG(Format, FORMAT, B8G8R8_SSCALED);
    SELECT_FLAG(Format, FORMAT, B8G8R8_UINT);
    SELECT_FLAG(Format, FORMAT, B8G8R8_SINT);
    SELECT_FLAG(Format, FORMAT, B8G8R8_SRGB);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_UNORM);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_SNORM);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_USCALED);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_SSCALED);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_UINT);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_SINT);
    SELECT_FLAG(Format, FORMAT, R8G8B8A8_SRGB);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_UNORM);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_SNORM);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_USCALED);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_SSCALED);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_UINT);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_SINT);
    SELECT_FLAG(Format, FORMAT, B8G8R8A8_SRGB);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_UNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_SNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_USCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_SSCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_UINT_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_SINT_PACK32);
    SELECT_FLAG(Format, FORMAT, A8B8G8R8_SRGB_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_UNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_SNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_USCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_SSCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_UINT_PACK32);
    SELECT_FLAG(Format, FORMAT, A2R10G10B10_SINT_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_UNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_SNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_USCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_SSCALED_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_UINT_PACK32);
    SELECT_FLAG(Format, FORMAT, A2B10G10R10_SINT_PACK32);
    SELECT_FLAG(Format, FORMAT, R16_UNORM);
    SELECT_FLAG(Format, FORMAT, R16_SNORM);
    SELECT_FLAG(Format, FORMAT, R16_USCALED);
    SELECT_FLAG(Format, FORMAT, R16_SSCALED);
    SELECT_FLAG(Format, FORMAT, R16_UINT);
    SELECT_FLAG(Format, FORMAT, R16_SINT);
    SELECT_FLAG(Format, FORMAT, R16_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R16G16_UNORM);
    SELECT_FLAG(Format, FORMAT, R16G16_SNORM);
    SELECT_FLAG(Format, FORMAT, R16G16_USCALED);
    SELECT_FLAG(Format, FORMAT, R16G16_SSCALED);
    SELECT_FLAG(Format, FORMAT, R16G16_UINT);
    SELECT_FLAG(Format, FORMAT, R16G16_SINT);
    SELECT_FLAG(Format, FORMAT, R16G16_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R16G16B16_UNORM);
    SELECT_FLAG(Format, FORMAT, R16G16B16_SNORM);
    SELECT_FLAG(Format, FORMAT, R16G16B16_USCALED);
    SELECT_FLAG(Format, FORMAT, R16G16B16_SSCALED);
    SELECT_FLAG(Format, FORMAT, R16G16B16_UINT);
    SELECT_FLAG(Format, FORMAT, R16G16B16_SINT);
    SELECT_FLAG(Format, FORMAT, R16G16B16_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_UNORM);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_SNORM);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_USCALED);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_SSCALED);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_UINT);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_SINT);
    SELECT_FLAG(Format, FORMAT, R16G16B16A16_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R32_UINT);
    SELECT_FLAG(Format, FORMAT, R32_SINT);
    SELECT_FLAG(Format, FORMAT, R32_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R32G32_UINT);
    SELECT_FLAG(Format, FORMAT, R32G32_SINT);
    SELECT_FLAG(Format, FORMAT, R32G32_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R32G32B32_UINT);
    SELECT_FLAG(Format, FORMAT, R32G32B32_SINT);
    SELECT_FLAG(Format, FORMAT, R32G32B32_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R32G32B32A32_UINT);
    SELECT_FLAG(Format, FORMAT, R32G32B32A32_SINT);
    SELECT_FLAG(Format, FORMAT, R32G32B32A32_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R64_UINT);
    SELECT_FLAG(Format, FORMAT, R64_SINT);
    SELECT_FLAG(Format, FORMAT, R64_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R64G64_UINT);
    SELECT_FLAG(Format, FORMAT, R64G64_SINT);
    SELECT_FLAG(Format, FORMAT, R64G64_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R64G64B64_UINT);
    SELECT_FLAG(Format, FORMAT, R64G64B64_SINT);
    SELECT_FLAG(Format, FORMAT, R64G64B64_SFLOAT);
    SELECT_FLAG(Format, FORMAT, R64G64B64A64_UINT);
    SELECT_FLAG(Format, FORMAT, R64G64B64A64_SINT);
    SELECT_FLAG(Format, FORMAT, R64G64B64A64_SFLOAT);
    SELECT_FLAG(Format, FORMAT, B10G11R11_UFLOAT_PACK32);
    SELECT_FLAG(Format, FORMAT, E5B9G9R9_UFLOAT_PACK32);
    SELECT_FLAG(Format, FORMAT, D16_UNORM);
    SELECT_FLAG(Format, FORMAT, X8_D24_UNORM_PACK32);
    SELECT_FLAG(Format, FORMAT, D32_SFLOAT);
    SELECT_FLAG(Format, FORMAT, S8_UINT);
    SELECT_FLAG(Format, FORMAT, D16_UNORM_S8_UINT);
    SELECT_FLAG(Format, FORMAT, D24_UNORM_S8_UINT);
    SELECT_FLAG(Format, FORMAT, D32_SFLOAT_S8_UINT);
    SELECT_FLAG(Format, FORMAT, BC1_RGB_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC1_RGB_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC1_RGBA_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC1_RGBA_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC2_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC2_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC3_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC3_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC4_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC4_SNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC5_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC5_SNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC6H_UFLOAT_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC6H_SFLOAT_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC7_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, BC7_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8A1_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8A1_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8A8_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ETC2_R8G8B8A8_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, EAC_R11_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, EAC_R11_SNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, EAC_R11G11_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, EAC_R11G11_SNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_4x4_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_4x4_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_5x4_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_5x4_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_5x5_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_5x5_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_6x5_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_6x5_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_6x6_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_6x6_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x5_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x5_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x6_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x6_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x8_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_8x8_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x5_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x5_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x6_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x6_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x8_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x8_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x10_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_10x10_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_12x10_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_12x10_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_12x12_UNORM_BLOCK);
    SELECT_FLAG(Format, FORMAT, ASTC_12x12_SRGB_BLOCK);
    SELECT_FLAG(Format, FORMAT, G8B8G8R8_422_UNORM);
    SELECT_FLAG(Format, FORMAT, B8G8R8G8_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_420_UNORM);
    SELECT_FLAG(Format, FORMAT, G8_B8R8_2PLANE_420_UNORM);
    SELECT_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G8_B8R8_2PLANE_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_444_UNORM);
    SELECT_FLAG(Format, FORMAT, R10X6_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, R10X6G10X6_UNORM_2PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6B10X6G10X6R10X6_422_UNORM_4PACK16);
    SELECT_FLAG(Format, FORMAT, B10X6G10X6R10X6G10X6_422_UNORM_4PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, R12X4_UNORM_PACK16);
    SELECT_FLAG(Format, FORMAT, R12X4G12X4_UNORM_2PACK16);
    SELECT_FLAG(Format, FORMAT, R12X4G12X4B12X4A12X4_UNORM_4PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4B12X4G12X4R12X4_422_UNORM_4PACK16);
    SELECT_FLAG(Format, FORMAT, B12X4G12X4R12X4G12X4_422_UNORM_4PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16);
    SELECT_FLAG(Format, FORMAT, G16B16G16R16_422_UNORM);
    SELECT_FLAG(Format, FORMAT, B16G16R16G16_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_420_UNORM);
    SELECT_FLAG(Format, FORMAT, G16_B16R16_2PLANE_420_UNORM);
    SELECT_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G16_B16R16_2PLANE_422_UNORM);
    SELECT_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_444_UNORM);
    SELECT_FLAG(Format, FORMAT, PVRTC1_2BPP_UNORM_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC1_4BPP_UNORM_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC2_2BPP_UNORM_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC2_4BPP_UNORM_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC1_2BPP_SRGB_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC1_4BPP_SRGB_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC2_2BPP_SRGB_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, PVRTC2_4BPP_SRGB_BLOCK_IMG);
    SELECT_FLAG(Format, FORMAT, ASTC_4x4_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_5x4_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_5x5_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_6x5_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_6x6_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_8x5_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_8x6_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_10x5_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_10x6_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_10x8_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_10x10_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_12x10_SFLOAT_BLOCK_EXT);
    SELECT_FLAG(Format, FORMAT, ASTC_12x12_SFLOAT_BLOCK_EXT);
    return VK_FORMAT_UNDEFINED;
}

work::renderer::Format fromVkFormat(VkFormat format) {
    auto flag = format;
    SELECT_FROM_FLAG(Format, FORMAT, R4G4_UNORM_PACK8);
    SELECT_FROM_FLAG(Format, FORMAT, R4G4B4A4_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, B4G4R4A4_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R5G6B5_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, B5G6R5_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R5G5B5A1_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, B5G5R5A1_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, A1R5G5B5_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R8G8B8A8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8A8_SRGB);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_UNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_SNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_USCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_SSCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_UINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_SINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A8B8G8R8_SRGB_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_UNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_SNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_USCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_SSCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_UINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2R10G10B10_SINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_UNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_SNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_USCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_SSCALED_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_UINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, A2B10G10R10_SINT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, R16_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_SNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_USCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_SSCALED);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R16G16B16A16_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R32_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32A32_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32A32_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R32G32B32A32_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R64_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64A64_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64A64_SINT);
    SELECT_FROM_FLAG(Format, FORMAT, R64G64B64A64_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, B10G11R11_UFLOAT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, E5B9G9R9_UFLOAT_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, D16_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, X8_D24_UNORM_PACK32);
    SELECT_FROM_FLAG(Format, FORMAT, D32_SFLOAT);
    SELECT_FROM_FLAG(Format, FORMAT, S8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, D16_UNORM_S8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, D24_UNORM_S8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, D32_SFLOAT_S8_UINT);
    SELECT_FROM_FLAG(Format, FORMAT, BC1_RGB_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC1_RGB_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC1_RGBA_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC1_RGBA_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC2_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC2_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC3_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC3_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC4_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC4_SNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC5_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC5_SNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC6H_UFLOAT_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC6H_SFLOAT_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC7_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, BC7_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8A1_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8A1_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8A8_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ETC2_R8G8B8A8_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, EAC_R11_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, EAC_R11_SNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, EAC_R11G11_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, EAC_R11G11_SNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_4x4_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_4x4_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x4_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x4_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x5_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x5_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x5_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x5_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x6_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x6_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x5_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x5_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x6_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x6_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x8_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x8_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x5_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x5_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x6_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x6_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x8_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x8_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x10_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x10_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x10_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x10_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x12_UNORM_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x12_SRGB_BLOCK);
    SELECT_FROM_FLAG(Format, FORMAT, G8B8G8R8_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B8G8R8G8_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_420_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G8_B8R8_2PLANE_420_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G8_B8R8_2PLANE_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G8_B8_R8_3PLANE_444_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, R10X6_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R10X6G10X6_UNORM_2PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6B10X6G10X6R10X6_422_UNORM_4PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, B10X6G10X6R10X6G10X6_422_UNORM_4PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R12X4_UNORM_PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R12X4G12X4_UNORM_2PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, R12X4G12X4B12X4A12X4_UNORM_4PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4B12X4G12X4R12X4_422_UNORM_4PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, B12X4G12X4R12X4G12X4_422_UNORM_4PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16);
    SELECT_FROM_FLAG(Format, FORMAT, G16B16G16R16_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, B16G16R16G16_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_420_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G16_B16R16_2PLANE_420_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G16_B16R16_2PLANE_422_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, G16_B16_R16_3PLANE_444_UNORM);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC1_2BPP_UNORM_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC1_4BPP_UNORM_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC2_2BPP_UNORM_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC2_4BPP_UNORM_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC1_2BPP_SRGB_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC1_4BPP_SRGB_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC2_2BPP_SRGB_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, PVRTC2_4BPP_SRGB_BLOCK_IMG);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_4x4_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x4_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_5x5_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x5_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_6x6_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x5_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_8x6_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x5_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x6_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x8_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_10x10_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x10_SFLOAT_BLOCK_EXT);
    SELECT_FROM_FLAG(Format, FORMAT, ASTC_12x12_SFLOAT_BLOCK_EXT);
    return work::renderer::Format::UNDEFINED;
}

VkBufferUsageFlags toVkBufferUsageFlags(work::renderer::BufferUsageFlags flags) {
    VkBufferUsageFlags result = 0;
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, TRANSFER_SRC_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, TRANSFER_DST_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, UNIFORM_TEXEL_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, STORAGE_TEXEL_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, UNIFORM_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, STORAGE_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, INDEX_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, VERTEX_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, INDIRECT_BUFFER_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, SHADER_DEVICE_ADDRESS_BIT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, TRANSFORM_FEEDBACK_BUFFER_BIT_EXT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, CONDITIONAL_RENDERING_BIT_EXT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, RAY_TRACING_BIT_NV);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, SHADER_DEVICE_ADDRESS_BIT_EXT);
    ADD_FLAG_BIT(BufferUsage, BUFFER_USAGE, SHADER_DEVICE_ADDRESS_BIT_KHR);

    return result;
}

VkImageUsageFlags toVkImageUsageFlags(work::renderer::ImageUsageFlags flags) {
    VkImageUsageFlags result = 0;
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, TRANSFER_SRC_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, TRANSFER_DST_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, SAMPLED_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, STORAGE_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, COLOR_ATTACHMENT_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, DEPTH_STENCIL_ATTACHMENT_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, TRANSIENT_ATTACHMENT_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, INPUT_ATTACHMENT_BIT);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, SHADING_RATE_IMAGE_BIT_NV);
    ADD_FLAG_BIT(ImageUsage, IMAGE_USAGE, FRAGMENT_DENSITY_MAP_BIT_EXT);

    return result;
}

VkImageCreateFlags toVkImageCreateFlags(work::renderer::ImageCreateFlags flags) {
    VkImageCreateFlags result = 0;
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SPARSE_BINDING_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SPARSE_RESIDENCY_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SPARSE_ALIASED_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, MUTABLE_FORMAT_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, CUBE_COMPATIBLE_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, ALIAS_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SPLIT_INSTANCE_BIND_REGIONS_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, BLOCK_TEXEL_VIEW_COMPATIBLE_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, EXTENDED_USAGE_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, PROTECTED_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, DISJOINT_BIT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, CORNER_SAMPLED_BIT_NV);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT);
    ADD_FLAG_BIT(ImageCreate, IMAGE_CREATE, SUBSAMPLED_BIT_EXT);
    result |= (flags & static_cast<uint32_t>(work::renderer::ImageCreateFlagBits::TWO_D_ARRAY_COMPATIBLE_BIT)) ? 
        VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT : 0;

    return result;
}

VkImageTiling toVkImageTiling(work::renderer::ImageTiling tiling) {
    if (tiling == work::renderer::ImageTiling::LINEAR) return VK_IMAGE_TILING_LINEAR;
    else if (tiling == work::renderer::ImageTiling::DRM_FORMAT_MODIFIER_EXT) return VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT;
    else return VK_IMAGE_TILING_OPTIMAL;
}

VkImageLayout toVkImageLayout(work::renderer::ImageLayout layout) {
    if (layout == work::renderer::ImageLayout::GENERAL) return VK_IMAGE_LAYOUT_GENERAL;
    else if (layout == work::renderer::ImageLayout::COLOR_ATTACHMENT_OPTIMAL) return VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::DEPTH_STENCIL_ATTACHMENT_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::DEPTH_STENCIL_READ_ONLY_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::SHADER_READ_ONLY_OPTIMAL) return VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::TRANSFER_SRC_OPTIMAL) return VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::TRANSFER_DST_OPTIMAL) return VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::PREINITIALIZED) return VK_IMAGE_LAYOUT_PREINITIALIZED;
    else if (layout == work::renderer::ImageLayout::DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::DEPTH_ATTACHMENT_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::DEPTH_READ_ONLY_OPTIMAL) return VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::STENCIL_ATTACHMENT_OPTIMAL) return VK_IMAGE_LAYOUT_STENCIL_ATTACHMENT_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::STENCIL_READ_ONLY_OPTIMAL) return VK_IMAGE_LAYOUT_STENCIL_READ_ONLY_OPTIMAL;
    else if (layout == work::renderer::ImageLayout::PRESENT_SRC_KHR) return VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
    else if (layout == work::renderer::ImageLayout::SHARED_PRESENT_KHR) return VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR;
    else if (layout == work::renderer::ImageLayout::SHADING_RATE_OPTIMAL_NV) return VK_IMAGE_LAYOUT_SHADING_RATE_OPTIMAL_NV;
    else if (layout == work::renderer::ImageLayout::FRAGMENT_DENSITY_MAP_OPTIMAL_EXT) return VK_IMAGE_LAYOUT_FRAGMENT_DENSITY_MAP_OPTIMAL_EXT;
    return VK_IMAGE_LAYOUT_UNDEFINED;
}

VkShaderStageFlagBits toVkShaderStageFlagBits(work::renderer::ShaderStageFlagBits stage) {
    if (stage == work::renderer::ShaderStageFlagBits::VERTEX_BIT) return VK_SHADER_STAGE_VERTEX_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::TESSELLATION_CONTROL_BIT) return VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::TESSELLATION_EVALUATION_BIT) return VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::GEOMETRY_BIT) return VK_SHADER_STAGE_GEOMETRY_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::FRAGMENT_BIT) return VK_SHADER_STAGE_FRAGMENT_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::COMPUTE_BIT) return VK_SHADER_STAGE_COMPUTE_BIT;
    else if (stage == work::renderer::ShaderStageFlagBits::ALL_GRAPHICS) return VK_SHADER_STAGE_ALL_GRAPHICS;
    else if (stage == work::renderer::ShaderStageFlagBits::ALL) return VK_SHADER_STAGE_ALL;
    else if (stage == work::renderer::ShaderStageFlagBits::RAYGEN_BIT_KHR) return VK_SHADER_STAGE_RAYGEN_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::ANY_HIT_BIT_KHR) return VK_SHADER_STAGE_ANY_HIT_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::CLOSEST_HIT_BIT_KHR) return VK_SHADER_STAGE_CLOSEST_HIT_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::MISS_BIT_KHR) return VK_SHADER_STAGE_MISS_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::INTERSECTION_BIT_KHR) return VK_SHADER_STAGE_INTERSECTION_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::CALLABLE_BIT_KHR) return VK_SHADER_STAGE_CALLABLE_BIT_KHR;
    else if (stage == work::renderer::ShaderStageFlagBits::TASK_BIT_NV) return VK_SHADER_STAGE_TASK_BIT_NV;
    else if (stage == work::renderer::ShaderStageFlagBits::MESH_BIT_NV) return VK_SHADER_STAGE_MESH_BIT_NV;
    else if (stage == work::renderer::ShaderStageFlagBits::MESH_BIT_NV) return VK_SHADER_STAGE_MESH_BIT_NV;
    return VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM;
};

VkMemoryPropertyFlags toVkMemoryPropertyFlags(work::renderer::MemoryPropertyFlags flags) {
    VkMemoryPropertyFlags result = 0;
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, DEVICE_LOCAL_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, HOST_VISIBLE_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, HOST_COHERENT_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, HOST_CACHED_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, LAZILY_ALLOCATED_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, PROTECTED_BIT);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, DEVICE_COHERENT_BIT_AMD);
    ADD_FLAG_BIT(MemoryProperty, MEMORY_PROPERTY, DEVICE_UNCACHED_BIT_AMD);

    return result;
}

VkCommandBufferUsageFlags toCommandBufferUsageFlags(work::renderer::CommandBufferUsageFlags flags) {
    VkCommandBufferUsageFlags result = 0;
    ADD_FLAG_BIT(CommandBufferUsage, COMMAND_BUFFER_USAGE, ONE_TIME_SUBMIT_BIT);
    ADD_FLAG_BIT(CommandBufferUsage, COMMAND_BUFFER_USAGE, RENDER_PASS_CONTINUE_BIT);
    ADD_FLAG_BIT(CommandBufferUsage, COMMAND_BUFFER_USAGE, SIMULTANEOUS_USE_BIT);

    return result;
}

VkImageType toVkImageType(work::renderer::ImageType view_type) {
    if (view_type == work::renderer::ImageType::TYPE_1D) return VK_IMAGE_TYPE_1D;
    else if (view_type == work::renderer::ImageType::TYPE_2D) return VK_IMAGE_TYPE_2D;
    return VK_IMAGE_TYPE_3D;
}

VkImageViewType toVkImageViewType(work::renderer::ImageViewType view_type) {
    auto flag = view_type;
    if (view_type == work::renderer::ImageViewType::VIEW_1D) return VK_IMAGE_VIEW_TYPE_1D;
    else if (view_type == work::renderer::ImageViewType::VIEW_2D) return VK_IMAGE_VIEW_TYPE_2D;
    else if (view_type == work::renderer::ImageViewType::VIEW_3D) return VK_IMAGE_VIEW_TYPE_3D;
    else if (view_type == work::renderer::ImageViewType::VIEW_CUBE) return VK_IMAGE_VIEW_TYPE_CUBE;
    else if (view_type == work::renderer::ImageViewType::VIEW_1D_ARRAY) return VK_IMAGE_VIEW_TYPE_1D_ARRAY;
    else if (view_type == work::renderer::ImageViewType::VIEW_2D_ARRAY) return VK_IMAGE_VIEW_TYPE_2D_ARRAY;
    else if (view_type == work::renderer::ImageViewType::VIEW_CUBE_ARRAY) return VK_IMAGE_VIEW_TYPE_CUBE_ARRAY;
    return VK_IMAGE_VIEW_TYPE_2D;
}

VkImageAspectFlags toVkImageAspectFlags(work::renderer::ImageAspectFlags flags) {
    VkImageAspectFlags result = 0;
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, COLOR_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, DEPTH_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, STENCIL_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, METADATA_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, PLANE_0_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, PLANE_1_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, PLANE_2_BIT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, MEMORY_PLANE_0_BIT_EXT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, MEMORY_PLANE_1_BIT_EXT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, MEMORY_PLANE_2_BIT_EXT);
    ADD_FLAG_BIT(ImageAspect, IMAGE_ASPECT, MEMORY_PLANE_3_BIT_EXT);
    return result;
}

VkAccessFlags toVkAccessFlags(work::renderer::AccessFlags flags) {
    VkAccessFlags result = 0;
    ADD_FLAG_BIT(Access, ACCESS, INDIRECT_COMMAND_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, INDEX_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, VERTEX_ATTRIBUTE_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, UNIFORM_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, INPUT_ATTACHMENT_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, SHADER_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, SHADER_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, COLOR_ATTACHMENT_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, COLOR_ATTACHMENT_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, DEPTH_STENCIL_ATTACHMENT_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, DEPTH_STENCIL_ATTACHMENT_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, TRANSFER_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, TRANSFER_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, HOST_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, HOST_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, MEMORY_READ_BIT);
    ADD_FLAG_BIT(Access, ACCESS, MEMORY_WRITE_BIT);
    ADD_FLAG_BIT(Access, ACCESS, TRANSFORM_FEEDBACK_WRITE_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, CONDITIONAL_RENDERING_READ_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, ACCELERATION_STRUCTURE_READ_BIT_KHR);
    ADD_FLAG_BIT(Access, ACCESS, ACCELERATION_STRUCTURE_WRITE_BIT_KHR);
    ADD_FLAG_BIT(Access, ACCESS, SHADING_RATE_IMAGE_READ_BIT_NV);
    ADD_FLAG_BIT(Access, ACCESS, FRAGMENT_DENSITY_MAP_READ_BIT_EXT);
    ADD_FLAG_BIT(Access, ACCESS, COMMAND_PREPROCESS_READ_BIT_NV);
    ADD_FLAG_BIT(Access, ACCESS, COMMAND_PREPROCESS_WRITE_BIT_NV);
    return result;
}

VkPipelineStageFlags toVkPipelineStageFlags(work::renderer::PipelineStageFlags flags) {
    VkPipelineStageFlags result = 0;
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TOP_OF_PIPE_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, DRAW_INDIRECT_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, VERTEX_INPUT_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, VERTEX_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TESSELLATION_CONTROL_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TESSELLATION_EVALUATION_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, GEOMETRY_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, FRAGMENT_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, EARLY_FRAGMENT_TESTS_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, LATE_FRAGMENT_TESTS_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, COLOR_ATTACHMENT_OUTPUT_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, COMPUTE_SHADER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TRANSFER_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, BOTTOM_OF_PIPE_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, HOST_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, ALL_GRAPHICS_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, ALL_COMMANDS_BIT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TRANSFORM_FEEDBACK_BIT_EXT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, CONDITIONAL_RENDERING_BIT_EXT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, RAY_TRACING_SHADER_BIT_KHR);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, ACCELERATION_STRUCTURE_BUILD_BIT_KHR);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, SHADING_RATE_IMAGE_BIT_NV);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, TASK_SHADER_BIT_NV);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, MESH_SHADER_BIT_NV);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, FRAGMENT_DENSITY_PROCESS_BIT_EXT);
    ADD_FLAG_BIT(PipelineStage, PIPELINE_STAGE, COMMAND_PREPROCESS_BIT_NV);
    return result;
};

VkShaderStageFlags toVkShaderStageFlags(work::renderer::ShaderStageFlags flags) {
    VkShaderStageFlags result = 0;
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, VERTEX_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, TESSELLATION_CONTROL_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, TESSELLATION_EVALUATION_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, GEOMETRY_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, FRAGMENT_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, COMPUTE_BIT);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, RAYGEN_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, ANY_HIT_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, CLOSEST_HIT_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, MISS_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, INTERSECTION_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, CALLABLE_BIT_KHR);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, TASK_BIT_NV);
    ADD_FLAG_BIT(ShaderStage, SHADER_STAGE, MESH_BIT_NV);

    return result;
}

VkPipelineBindPoint toVkPipelineBindPoint(work::renderer::PipelineBindPoint bind) {
    if (bind == work::renderer::PipelineBindPoint::COMPUTE) return VK_PIPELINE_BIND_POINT_COMPUTE;
    else if (bind == work::renderer::PipelineBindPoint::RAY_TRACING) return VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR;
    return VK_PIPELINE_BIND_POINT_GRAPHICS;
}

VkCommandPoolCreateFlags toVkCommandPoolCreateFlags(work::renderer::CommandPoolCreateFlags flags) {
    VkCommandPoolCreateFlags result = 0;
    ADD_FLAG_BIT(CommandPoolCreate, COMMAND_POOL_CREATE, TRANSIENT_BIT);
    ADD_FLAG_BIT(CommandPoolCreate, COMMAND_POOL_CREATE, RESET_COMMAND_BUFFER_BIT);
    ADD_FLAG_BIT(CommandPoolCreate, COMMAND_POOL_CREATE, PROTECTED_BIT);
    return result;
}

VkFilter toVkFilter(work::renderer::Filter filter) {
    if (filter == work::renderer::Filter::NEAREST) return VK_FILTER_NEAREST;
    else if (filter == work::renderer::Filter::CUBIC_IMG) return VK_FILTER_CUBIC_IMG;
    return VK_FILTER_LINEAR;
}

VkDescriptorType toVkDescriptorType(work::renderer::DescriptorType type) {
    if (type == work::renderer::DescriptorType::SAMPLER) return VK_DESCRIPTOR_TYPE_SAMPLER;
    else if (type == work::renderer::DescriptorType::COMBINED_IMAGE_SAMPLER) return VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
    else if (type == work::renderer::DescriptorType::SAMPLED_IMAGE) return VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE;
    else if (type == work::renderer::DescriptorType::STORAGE_IMAGE) return VK_DESCRIPTOR_TYPE_STORAGE_IMAGE;
    else if (type == work::renderer::DescriptorType::UNIFORM_TEXEL_BUFFER) return VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER;
    else if (type == work::renderer::DescriptorType::STORAGE_TEXEL_BUFFER) return VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER;
    else if (type == work::renderer::DescriptorType::UNIFORM_BUFFER) return VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
    else if (type == work::renderer::DescriptorType::STORAGE_BUFFER) return VK_DESCRIPTOR_TYPE_STORAGE_BUFFER;
    else if (type == work::renderer::DescriptorType::UNIFORM_BUFFER_DYNAMIC) return VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC;
    else if (type == work::renderer::DescriptorType::STORAGE_BUFFER_DYNAMIC) return VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC;
    else if (type == work::renderer::DescriptorType::INPUT_ATTACHMENT) return VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT;
    else if (type == work::renderer::DescriptorType::INLINE_UNIFORM_BLOCK_EXT) return VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT;
    else if (type == work::renderer::DescriptorType::ACCELERATION_STRUCTURE_KHR) return VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_KHR;
    return VK_DESCRIPTOR_TYPE_SAMPLER;
}

VkSamplerAddressMode toVkSamplerAddressMode(work::renderer::SamplerAddressMode mode) {
    if (mode == work::renderer::SamplerAddressMode::MIRRORED_REPEAT) return VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT;
    else if (mode == work::renderer::SamplerAddressMode::CLAMP_TO_EDGE) return VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
    else if (mode == work::renderer::SamplerAddressMode::CLAMP_TO_BORDER) return VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER;
    else if (mode == work::renderer::SamplerAddressMode::MIRROR_CLAMP_TO_EDGE) return VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE;
    return VK_SAMPLER_ADDRESS_MODE_REPEAT;
}

VkSamplerMipmapMode toVkSamplerMipmapMode(work::renderer::SamplerMipmapMode mode) {
    if (mode == work::renderer::SamplerMipmapMode::NEAREST) return VK_SAMPLER_MIPMAP_MODE_NEAREST;
    return VK_SAMPLER_MIPMAP_MODE_LINEAR;
}

VkColorSpaceKHR toVkColorSpace(work::renderer::ColorSpace color_space) {
    if (color_space == work::renderer::ColorSpace::DISPLAY_P3_NONLINEAR_EXT) return VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::DISPLAY_P3_LINEAR_EXT) return VK_COLOR_SPACE_DISPLAY_P3_LINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::DCI_P3_NONLINEAR_EXT) return VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::BT709_LINEAR_EXT) return VK_COLOR_SPACE_BT709_LINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::BT709_NONLINEAR_EXT) return VK_COLOR_SPACE_BT709_NONLINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::BT2020_LINEAR_EXT) return VK_COLOR_SPACE_BT2020_LINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::HDR10_ST2084_EXT) return VK_COLOR_SPACE_HDR10_ST2084_EXT;
    else if (color_space == work::renderer::ColorSpace::DOLBYVISION_EXT) return VK_COLOR_SPACE_DOLBYVISION_EXT;
    else if (color_space == work::renderer::ColorSpace::HDR10_HLG_EXT) return VK_COLOR_SPACE_HDR10_HLG_EXT;
    else if (color_space == work::renderer::ColorSpace::ADOBERGB_LINEAR_EXT) return VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::ADOBERGB_NONLINEAR_EXT) return VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::PASS_THROUGH_EXT) return VK_COLOR_SPACE_PASS_THROUGH_EXT;
    else if (color_space == work::renderer::ColorSpace::EXTENDED_SRGB_NONLINEAR_EXT) return VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT;
    else if (color_space == work::renderer::ColorSpace::DISPLAY_NATIVE_AMD) return VK_COLOR_SPACE_DISPLAY_NATIVE_AMD;
    return VK_COLOR_SPACE_SRGB_NONLINEAR_KHR;
}

work::renderer::ColorSpace fromVkColorSpace(VkColorSpaceKHR color_space) {
    if (color_space == VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT) return work::renderer::ColorSpace::DISPLAY_P3_NONLINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_DISPLAY_P3_LINEAR_EXT) return work::renderer::ColorSpace::DISPLAY_P3_LINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT) return work::renderer::ColorSpace::DCI_P3_NONLINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_BT709_LINEAR_EXT) return work::renderer::ColorSpace::BT709_LINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_BT709_NONLINEAR_EXT) return work::renderer::ColorSpace::BT709_NONLINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_BT2020_LINEAR_EXT) return work::renderer::ColorSpace::BT2020_LINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_HDR10_ST2084_EXT) return work::renderer::ColorSpace::HDR10_ST2084_EXT;
    else if (color_space == VK_COLOR_SPACE_DOLBYVISION_EXT) return work::renderer::ColorSpace::DOLBYVISION_EXT;
    else if (color_space == VK_COLOR_SPACE_HDR10_HLG_EXT) return work::renderer::ColorSpace::HDR10_HLG_EXT;
    else if (color_space == VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT) return work::renderer::ColorSpace::ADOBERGB_LINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT) return work::renderer::ColorSpace::ADOBERGB_NONLINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_PASS_THROUGH_EXT) return work::renderer::ColorSpace::PASS_THROUGH_EXT;
    else if (color_space == VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT) return work::renderer::ColorSpace::EXTENDED_SRGB_NONLINEAR_EXT;
    else if (color_space == VK_COLOR_SPACE_DISPLAY_NATIVE_AMD) return work::renderer::ColorSpace::DISPLAY_NATIVE_AMD;
    return work::renderer::ColorSpace::SRGB_NONLINEAR_KHR;
}

VkPresentModeKHR toVkPresentMode(work::renderer::PresentMode mode) {
    if (mode == work::renderer::PresentMode::MAILBOX_KHR) return VK_PRESENT_MODE_MAILBOX_KHR;
    else if (mode == work::renderer::PresentMode::FIFO_KHR) return VK_PRESENT_MODE_FIFO_KHR;
    else if (mode == work::renderer::PresentMode::FIFO_RELAXED_KHR) return VK_PRESENT_MODE_FIFO_RELAXED_KHR;
    else if (mode == work::renderer::PresentMode::SHARED_DEMAND_REFRESH_KHR) return VK_PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR;
    else if (mode == work::renderer::PresentMode::SHARED_CONTINUOUS_REFRESH_KHR) return VK_PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR;
    return VK_PRESENT_MODE_IMMEDIATE_KHR;
}

VkSurfaceTransformFlagBitsKHR toVkSurfaceTransformFlags(work::renderer::SurfaceTransformFlagBits flag) {
    if (flag == work::renderer::SurfaceTransformFlagBits::ROTATE_90_BIT_KHR) return VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::ROTATE_180_BIT_KHR) return VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::ROTATE_270_BIT_KHR) return VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_BIT_KHR) return VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR) return VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR) return VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR) return VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR;
    else if (flag == work::renderer::SurfaceTransformFlagBits::INHERIT_BIT_KHR) return VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR;
    return VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR;
}

work::renderer::SurfaceTransformFlagBits fromVkSurfaceTransformFlags(VkSurfaceTransformFlagBitsKHR flag) {
    if (flag == VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::ROTATE_90_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::ROTATE_180_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::ROTATE_270_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR;
    else if (flag == VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR) return work::renderer::SurfaceTransformFlagBits::INHERIT_BIT_KHR;
    return work::renderer::SurfaceTransformFlagBits::IDENTITY_BIT_KHR;
}

VkColorComponentFlags toVkColorComponentFlags(renderer::ColorComponentFlags flags) {
    VkColorComponentFlags result = 0;
    ADD_FLAG_BIT(ColorComponent, COLOR_COMPONENT, R_BIT);
    ADD_FLAG_BIT(ColorComponent, COLOR_COMPONENT, G_BIT);
    ADD_FLAG_BIT(ColorComponent, COLOR_COMPONENT, B_BIT);
    ADD_FLAG_BIT(ColorComponent, COLOR_COMPONENT, A_BIT);
    return result;
}

VkPrimitiveTopology toVkPrimitiveTopology(renderer::PrimitiveTopology primitive) {
    auto flag = primitive;
    SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, LINE_LIST);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, LINE_STRIP);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, TRIANGLE_LIST);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, TRIANGLE_STRIP);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, TRIANGLE_FAN);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, LINE_LIST_WITH_ADJACENCY);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, LINE_STRIP_WITH_ADJACENCY);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, TRIANGLE_LIST_WITH_ADJACENCY);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, TRIANGLE_STRIP_WITH_ADJACENCY);
    else SELECT_FLAG(PrimitiveTopology, PRIMITIVE_TOPOLOGY, PATCH_LIST);
    return VK_PRIMITIVE_TOPOLOGY_POINT_LIST;
}

VkBlendFactor toVkBlendFactor(renderer::BlendFactor blend_factor) {
    auto flag = blend_factor;
    SELECT_FLAG(BlendFactor, BLEND_FACTOR, ZERO);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, SRC_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_SRC_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, DST_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_DST_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, SRC_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_SRC_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, DST_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_DST_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, CONSTANT_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_CONSTANT_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, CONSTANT_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_CONSTANT_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, SRC_ALPHA_SATURATE);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, SRC1_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_SRC1_COLOR);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, SRC1_ALPHA);
    else SELECT_FLAG(BlendFactor, BLEND_FACTOR, ONE_MINUS_SRC1_ALPHA);
    return VK_BLEND_FACTOR_ZERO;
}

VkBlendOp toVkBlendOp(renderer::BlendOp blend_op) {
    auto flag = blend_op;
    SELECT_FLAG(BlendOp, BLEND_OP, ADD);
    else SELECT_FLAG(BlendOp, BLEND_OP, SUBTRACT);
    else SELECT_FLAG(BlendOp, BLEND_OP, REVERSE_SUBTRACT);
    else SELECT_FLAG(BlendOp, BLEND_OP, MIN);
    else SELECT_FLAG(BlendOp, BLEND_OP, MAX);
    else SELECT_FLAG(BlendOp, BLEND_OP, ZERO_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SRC_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DST_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SRC_OVER_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DST_OVER_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SRC_IN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DST_IN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SRC_OUT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DST_OUT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SRC_ATOP_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DST_ATOP_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, XOR_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, MULTIPLY_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SCREEN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, OVERLAY_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DARKEN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, LIGHTEN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, COLORDODGE_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, COLORBURN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HARDLIGHT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, SOFTLIGHT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, DIFFERENCE_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, EXCLUSION_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, INVERT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, INVERT_RGB_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, LINEARDODGE_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, LINEARBURN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, VIVIDLIGHT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, LINEARLIGHT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, PINLIGHT_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HARDMIX_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HSL_HUE_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HSL_SATURATION_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HSL_COLOR_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, HSL_LUMINOSITY_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, PLUS_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, PLUS_CLAMPED_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, PLUS_CLAMPED_ALPHA_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, PLUS_DARKER_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, MINUS_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, MINUS_CLAMPED_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, CONTRAST_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, INVERT_OVG_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, RED_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, GREEN_EXT);
    else SELECT_FLAG(BlendOp, BLEND_OP, BLUE_EXT);
    return VK_BLEND_OP_ADD;
};

VkIndexType toVkIndexType(work::renderer::IndexType index_type) {
    auto flag = index_type;
    SELECT_FLAG(IndexType, INDEX_TYPE, UINT32);
    else SELECT_FLAG(IndexType, INDEX_TYPE, NONE_KHR);
    else SELECT_FLAG(IndexType, INDEX_TYPE, UINT8_EXT);
    return VK_INDEX_TYPE_UINT16;
}

VkVertexInputRate toVkVertexInputRate(renderer::VertexInputRate input_rate) {
    auto flag = input_rate;
    SELECT_FLAG(VertexInputRate, VERTEX_INPUT_RATE, INSTANCE);
    return VK_VERTEX_INPUT_RATE_VERTEX;
}

VkLogicOp toVkLogicOp(renderer::LogicOp logic_op) {
    auto flag = logic_op;
    SELECT_FLAG(LogicOp, LOGIC_OP, CLEAR);
    else SELECT_FLAG(LogicOp, LOGIC_OP, AND);
    else SELECT_FLAG(LogicOp, LOGIC_OP, AND_REVERSE);
    else SELECT_FLAG(LogicOp, LOGIC_OP, COPY);
    else SELECT_FLAG(LogicOp, LOGIC_OP, AND_INVERTED);
    else SELECT_FLAG(LogicOp, LOGIC_OP, NO_OP);
    else SELECT_FLAG(LogicOp, LOGIC_OP, XOR);
    else SELECT_FLAG(LogicOp, LOGIC_OP, OR);
    else SELECT_FLAG(LogicOp, LOGIC_OP, NOR);
    else SELECT_FLAG(LogicOp, LOGIC_OP, EQUIVALENT);
    else SELECT_FLAG(LogicOp, LOGIC_OP, INVERT);
    else SELECT_FLAG(LogicOp, LOGIC_OP, OR_REVERSE);
    else SELECT_FLAG(LogicOp, LOGIC_OP, COPY_INVERTED);
    else SELECT_FLAG(LogicOp, LOGIC_OP, OR_INVERTED);
    else SELECT_FLAG(LogicOp, LOGIC_OP, NAND);
    else SELECT_FLAG(LogicOp, LOGIC_OP, SET);
    return VK_LOGIC_OP_NO_OP;
}

VkPolygonMode toVkPolygonMode(renderer::PolygonMode polygon_mode) {
    auto flag = polygon_mode;
    SELECT_FLAG(PolygonMode, POLYGON_MODE, FILL);
    else SELECT_FLAG(PolygonMode, POLYGON_MODE, LINE);
    else SELECT_FLAG(PolygonMode, POLYGON_MODE, POINT);
    else SELECT_FLAG(PolygonMode, POLYGON_MODE, FILL_RECTANGLE_NV);
    return VK_POLYGON_MODE_FILL;
};

VkCullModeFlags toVkCullModeFlags(renderer::CullModeFlags flags) {
    VkCullModeFlags result = 0;
    ADD_FLAG_BIT(CullMode, CULL_MODE, NONE);
    ADD_FLAG_BIT(CullMode, CULL_MODE, FRONT_BIT);
    ADD_FLAG_BIT(CullMode, CULL_MODE, BACK_BIT);
    return result;
}

VkFrontFace toVkFrontFace(renderer::FrontFace front_face) {
    auto flag = front_face;
    SELECT_FLAG(FrontFace, FRONT_FACE, COUNTER_CLOCKWISE);
    SELECT_FLAG(FrontFace, FRONT_FACE, CLOCKWISE);
    return VK_FRONT_FACE_CLOCKWISE;
}

VkSampleCountFlags toVkSampleCountFlags(renderer::SampleCountFlags flags) {
    VkSampleCountFlags result = 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_1_BIT)) ? VK_SAMPLE_COUNT_1_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_2_BIT)) ? VK_SAMPLE_COUNT_2_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_4_BIT)) ? VK_SAMPLE_COUNT_4_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_8_BIT)) ? VK_SAMPLE_COUNT_8_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_16_BIT)) ? VK_SAMPLE_COUNT_16_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_32_BIT)) ? VK_SAMPLE_COUNT_32_BIT : 0;
    result |= (flags & static_cast<uint32_t>(renderer::SampleCountFlagBits::SC_64_BIT)) ? VK_SAMPLE_COUNT_64_BIT : 0;
    return result;
}

VkCompareOp toVkCompareOp(renderer::CompareOp compare_op) {
    auto flag = compare_op;
    SELECT_FLAG(CompareOp, COMPARE_OP, NEVER);
    else SELECT_FLAG(CompareOp, COMPARE_OP, LESS);
    else SELECT_FLAG(CompareOp, COMPARE_OP, EQUAL);
    else SELECT_FLAG(CompareOp, COMPARE_OP, LESS_OR_EQUAL);
    else SELECT_FLAG(CompareOp, COMPARE_OP, GREATER);
    else SELECT_FLAG(CompareOp, COMPARE_OP, NOT_EQUAL);
    else SELECT_FLAG(CompareOp, COMPARE_OP, GREATER_OR_EQUAL);
    else SELECT_FLAG(CompareOp, COMPARE_OP, ALWAYS);
    return VK_COMPARE_OP_LESS;
}

VkStencilOp toVkStencilOp(renderer::StencilOp stencil_op) {
    auto flag = stencil_op;
    SELECT_FLAG(StencilOp, STENCIL_OP, KEEP);
    else SELECT_FLAG(StencilOp, STENCIL_OP, ZERO);
    else SELECT_FLAG(StencilOp, STENCIL_OP, REPLACE);
    else SELECT_FLAG(StencilOp, STENCIL_OP, INCREMENT_AND_CLAMP);
    else SELECT_FLAG(StencilOp, STENCIL_OP, DECREMENT_AND_CLAMP);
    else SELECT_FLAG(StencilOp, STENCIL_OP, INVERT);
    else SELECT_FLAG(StencilOp, STENCIL_OP, INCREMENT_AND_WRAP);
    else SELECT_FLAG(StencilOp, STENCIL_OP, DECREMENT_AND_WRAP);
    return VK_STENCIL_OP_KEEP;
}

VkAttachmentLoadOp toVkAttachmentLoadOp(renderer::AttachmentLoadOp load_op) {
    auto flag = load_op;
    SELECT_FLAG(AttachmentLoadOp, ATTACHMENT_LOAD_OP, LOAD);
    else SELECT_FLAG(AttachmentLoadOp, ATTACHMENT_LOAD_OP, CLEAR);
    else SELECT_FLAG(AttachmentLoadOp, ATTACHMENT_LOAD_OP, DONT_CARE);
    return VK_ATTACHMENT_LOAD_OP_DONT_CARE;
};

VkAttachmentStoreOp toVkAttachmentStoreOp(renderer::AttachmentStoreOp store_op) {
    auto flag = store_op;
    SELECT_FLAG(AttachmentStoreOp, ATTACHMENT_STORE_OP, STORE);
    else SELECT_FLAG(AttachmentStoreOp, ATTACHMENT_STORE_OP, DONT_CARE);
    else SELECT_FLAG(AttachmentStoreOp, ATTACHMENT_STORE_OP, NONE_QCOM);
    return VK_ATTACHMENT_STORE_OP_DONT_CARE;
}

VkAttachmentDescriptionFlags toVkAttachmentDescriptionFlags(renderer::AttachmentDescriptionFlags flags) {
    VkAttachmentDescriptionFlags result = 0;
    ADD_FLAG_BIT(AttachmentDescription, ATTACHMENT_DESCRIPTION, MAY_ALIAS_BIT);
    return result;
}

VkDependencyFlags toVkDependencyFlags(renderer::DependencyFlags flags) {
    VkDependencyFlags result = 0;
    ADD_FLAG_BIT(Dependency, DEPENDENCY, BY_REGION_BIT);
    ADD_FLAG_BIT(Dependency, DEPENDENCY, DEVICE_GROUP_BIT);
    ADD_FLAG_BIT(Dependency, DEPENDENCY, VIEW_LOCAL_BIT);
    ADD_FLAG_BIT(Dependency, DEPENDENCY, VIEW_LOCAL_BIT_KHR);
    ADD_FLAG_BIT(Dependency, DEPENDENCY, DEVICE_GROUP_BIT_KHR);
    return result;
}

VkSubpassDescriptionFlags toVkSubpassDescriptionFlags(renderer::SubpassDescriptionFlags flags) {
    VkSubpassDescriptionFlags result = 0;
    ADD_FLAG_BIT(SubpassDescription, SUBPASS_DESCRIPTION, PER_VIEW_ATTRIBUTES_BIT_NVX);
    ADD_FLAG_BIT(SubpassDescription, SUBPASS_DESCRIPTION, PER_VIEW_POSITION_X_ONLY_BIT_NVX);
    ADD_FLAG_BIT(SubpassDescription, SUBPASS_DESCRIPTION, FRAGMENT_REGION_BIT_QCOM);
    ADD_FLAG_BIT(SubpassDescription, SUBPASS_DESCRIPTION, SHADER_RESOLVE_BIT_QCOM);
    return result;
}

std::vector<VkVertexInputBindingDescription> toVkVertexInputBindingDescription(
    const std::vector<work::renderer::VertexInputBindingDescription>& description) {
    std::vector<VkVertexInputBindingDescription> binding_description(description.size());
    for (int i = 0; i < description.size(); i++) {
        binding_description[i].binding = description[i].binding;
        binding_description[i].stride = description[i].stride;
        binding_description[i].inputRate = toVkVertexInputRate(description[i].input_rate);
    }
    return binding_description;
}

std::vector<VkVertexInputAttributeDescription> toVkVertexInputAttributeDescription(
    const std::vector<work::renderer::VertexInputAttributeDescription>& description) {
    std::vector<VkVertexInputAttributeDescription> result(description.size());
    for (int i = 0; i < description.size(); i++) {
        result[i].binding = description[i].binding;
        result[i].location = description[i].location;
        result[i].offset = static_cast<uint32_t>(description[i].offset);
        result[i].format = toVkFormat(description[i].format);
    }

    return result;
}

struct SwapChainSupportDetails {
    VkSurfaceCapabilitiesKHR capabilities_;
    std::vector<VkSurfaceFormatKHR> formats_;
    std::vector<VkPresentModeKHR> present_modes_;
};

const std::vector<const char*> validation_layers = {
    "VK_LAYER_KHRONOS_validation"
};

const std::vector<const char*> device_extensions = {
    VK_KHR_SWAPCHAIN_EXTENSION_NAME
};

#ifdef NDEBUG
const bool enable_validation_layers = false;
#else
const bool enable_validation_layers = true;
#endif


bool checkValidationLayerSupport() {
    uint32_t layer_count;
    vkEnumerateInstanceLayerProperties(&layer_count, nullptr);

    std::vector<VkLayerProperties> available_layers(layer_count);
    vkEnumerateInstanceLayerProperties(&layer_count, available_layers.data());

    for (const char* layer_name : validation_layers) {
        bool layer_found = false;

        for (const auto& layer_properties : available_layers) {
            if (strcmp(layer_name, layer_properties.layerName) == 0) {
                layer_found = true;
                break;
            }
        }

        if (!layer_found) {
            return false;
        }
    }

    return true;
}

std::vector<const char*> getRequiredExtensions() {
    uint32_t glfw_extensionCount = 0;
    const char** glfw_extensions;
    glfw_extensions = glfwGetRequiredInstanceExtensions(&glfw_extensionCount);

    std::vector<const char*> extensions(glfw_extensions, glfw_extensions + glfw_extensionCount);

    if (enable_validation_layers) {
        extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME);
    }

    if (0) {
        extensions.push_back(VK_KHR_ACCELERATION_STRUCTURE_EXTENSION_NAME);
        extensions.push_back(VK_KHR_RAY_TRACING_PIPELINE_EXTENSION_NAME);
        extensions.push_back(VK_KHR_MAINTENANCE3_EXTENSION_NAME);
        extensions.push_back(VK_KHR_PIPELINE_LIBRARY_EXTENSION_NAME);
        extensions.push_back(VK_KHR_DEFERRED_HOST_OPERATIONS_EXTENSION_NAME);
        extensions.push_back(VK_KHR_BUFFER_DEVICE_ADDRESS_EXTENSION_NAME);
    }
    return extensions;
}

static VKAPI_ATTR VkBool32 VKAPI_CALL debugCallback(
    VkDebugUtilsMessageSeverityFlagBitsEXT message_severity,
    VkDebugUtilsMessageTypeFlagsEXT message_type,
    const VkDebugUtilsMessengerCallbackDataEXT* p_callback_data,
    void* pUserData) {

    std::cerr << "validation layer: " << p_callback_data->pMessage << std::endl;

    return VK_FALSE;
}

VkResult CreateDebugUtilsMessengerEXT(
    const VkInstance& instance,
    const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkDebugUtilsMessengerEXT* pDebugMessenger) {
    auto func = (PFN_vkCreateDebugUtilsMessengerEXT)vkGetInstanceProcAddr(instance, "vkCreateDebugUtilsMessengerEXT");
    if (func != nullptr) {
        return func(instance, pCreateInfo, pAllocator, pDebugMessenger);
    }
    else {
        return VK_ERROR_EXTENSION_NOT_PRESENT;
    }
}

void populateDebugMessengerCreateInfo(VkDebugUtilsMessengerCreateInfoEXT& create_info) {
    create_info = {};
    create_info.sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT;
    create_info.messageSeverity = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT;
    create_info.messageType = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT;
    create_info.pfnUserCallback = debugCallback;
}

std::shared_ptr<renderer::Instance> createInstance() {
    VkApplicationInfo app_info{};
    app_info.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
    app_info.pApplicationName = "Real World";
    app_info.applicationVersion = VK_MAKE_VERSION(1, 0, 0);
    app_info.pEngineName = "No Engine";
    app_info.engineVersion = VK_MAKE_VERSION(1, 0, 0);
    app_info.apiVersion = VK_API_VERSION_1_0;

    VkInstanceCreateInfo create_info{};
    create_info.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
    create_info.pApplicationInfo = &app_info;

#if 0
    uint32_t glfw_extensionCount = 0;
    const char** glfw_extensions;

    glfw_extensions = glfwGetRequiredInstanceExtensions(&glfw_extensionCount);

    create_info.enabledExtensionCount = glfw_extensionCount;
    create_info.ppEnabledExtensionNames = glfw_extensions;
    if (enable_validation_layers) {
        create_info.enabledLayerCount = static_cast<uint32_t>(validation_layers.size());
        create_info.ppEnabledLayerNames = validation_layers.data();
    }
    else {
        create_info.enabledLayerCount = 0;
    }
#else
    auto required_extensions = getRequiredExtensions();
    create_info.enabledExtensionCount = static_cast<uint32_t>(required_extensions.size());
    create_info.ppEnabledExtensionNames = required_extensions.data();

    VkDebugUtilsMessengerCreateInfoEXT debug_create_info;
    if (enable_validation_layers) {
        create_info.enabledLayerCount = static_cast<uint32_t>(validation_layers.size());
        create_info.ppEnabledLayerNames = validation_layers.data();

        populateDebugMessengerCreateInfo(debug_create_info);
        create_info.pNext = (VkDebugUtilsMessengerCreateInfoEXT*)&debug_create_info;
    }
    else {
        create_info.enabledLayerCount = 0;
        create_info.pNext = nullptr;
    }
#endif
    VkInstance instance;
    if (vkCreateInstance(&create_info, nullptr, &instance) != VK_SUCCESS) {
        throw std::runtime_error("failed to create instance!");
    }

    auto vk_instance = std::make_shared<renderer::VulkanInstance>();
    vk_instance->set(instance);

    uint32_t extension_count = 0;
    vkEnumerateInstanceExtensionProperties(nullptr, &extension_count, nullptr);
    std::vector<VkExtensionProperties> extensions(extension_count);
    vkEnumerateInstanceExtensionProperties(nullptr, &extension_count, extensions.data());

    std::cout << "available extensions:\n";

    for (const auto& extension : extensions) {
        std::cout << '\t' << extension.extensionName << '\n';
    }

    if (enable_validation_layers && !checkValidationLayerSupport()) {
        throw std::runtime_error("validation layers requested, but not available!");
    }

    if (enable_validation_layers) {
        VkDebugUtilsMessengerCreateInfoEXT create_info;
        populateDebugMessengerCreateInfo(create_info);

        VkDebugUtilsMessengerEXT debug_messenger;
        if (CreateDebugUtilsMessengerEXT(instance, &create_info, nullptr, &debug_messenger) != VK_SUCCESS) {
            throw std::runtime_error("failed to set up debug messenger!");
        }

        vk_instance->setDebugMessenger(debug_messenger);
    }

    return vk_instance;
}

std::shared_ptr<renderer::Surface> createSurface(
    const std::shared_ptr<renderer::Instance>& instance,
    GLFWwindow* window) {
    const auto& vk_instance = RENDER_TYPE_CAST(Instance, instance);
    assert(vk_instance);

    VkSurfaceKHR surface;
    if (glfwCreateWindowSurface(vk_instance->get(), window, nullptr, &surface) != VK_SUCCESS) {
        throw std::runtime_error("failed to create window surface!");
    }

    auto vk_surface = std::make_shared<renderer::VulkanSurface>();
    vk_surface->set(surface);
    
    return vk_surface;
}

void DestroyDebugUtilsMessengerEXT(const VkInstance& instance,
    VkDebugUtilsMessengerEXT debug_messenger,
    const VkAllocationCallbacks* pAllocator) {
    auto func = (PFN_vkDestroyDebugUtilsMessengerEXT)vkGetInstanceProcAddr(instance, "vkDestroyDebugUtilsMessengerEXT");
    if (func != nullptr) {
        func(instance, debug_messenger, pAllocator);
    }
}

renderer::PhysicalDeviceList collectPhysicalDevices(
    const std::shared_ptr<renderer::Instance>& instance) {

    const auto& vk_instance = RENDER_TYPE_CAST(Instance, instance);
    assert(vk_instance);

    uint32_t device_count = 0;
    vkEnumeratePhysicalDevices(vk_instance->get(), &device_count, nullptr);

    if (device_count == 0) {
        throw std::runtime_error("failed to find GPUs with Vulkan support!");
    }

    std::vector<VkPhysicalDevice> devices(device_count);
    vkEnumeratePhysicalDevices(vk_instance->get(), &device_count, devices.data());

    renderer::PhysicalDeviceList physical_devices;

    for (const auto& device : devices) {
        auto physical_device = std::make_shared<renderer::VulkanPhysicalDevice>();
        physical_device->set(device);
        physical_devices.push_back(physical_device);
    }

    return physical_devices;
}

renderer::QueueFamilyIndices findQueueFamilies(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    const std::shared_ptr<renderer::Surface>& surface) {
    renderer::QueueFamilyIndices indices;

    const auto& vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    auto device = vk_physical_device->get();

    auto vk_surface = RENDER_TYPE_CAST(Surface, surface);
    assert(vk_surface);

    uint32_t queue_family_count = 0;
    vkGetPhysicalDeviceQueueFamilyProperties(device, &queue_family_count, nullptr);

    std::vector<VkQueueFamilyProperties> queue_families(queue_family_count);
    vkGetPhysicalDeviceQueueFamilyProperties(device, &queue_family_count, queue_families.data());

    int i = 0;
    for (const auto& queue_family : queue_families) {
        if (queue_family.queueFlags & VK_QUEUE_GRAPHICS_BIT) {
            indices.graphics_family_ = i;
        }

        VkBool32 present_support = false;
        vkGetPhysicalDeviceSurfaceSupportKHR(device, i, vk_surface->get(), &present_support);

        if (present_support) {
            indices.present_family_ = i;
        }
        if (indices.isComplete()) {
            break;
        }

        i++;
    }

    return indices;
}

bool checkDeviceExtensionSupport(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device) {
    const auto& vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    auto device = vk_physical_device->get();

    uint32_t extension_count;
    vkEnumerateDeviceExtensionProperties(device, nullptr, &extension_count, nullptr);

    std::vector<VkExtensionProperties> available_extensions(extension_count);
    vkEnumerateDeviceExtensionProperties(device, nullptr, &extension_count, available_extensions.data());

    std::set<std::string> required_extensions(device_extensions.begin(), device_extensions.end());

    for (const auto& extension : available_extensions) {
        required_extensions.erase(extension.extensionName);
    }

    return required_extensions.empty();
}

SwapChainSupportDetails querySwapChainSupport(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    const std::shared_ptr<renderer::Surface>& surface) {
    SwapChainSupportDetails details;

    auto vk_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_device);
    auto device = vk_device->get();

    auto vk_surface = RENDER_TYPE_CAST(Surface, surface);
    assert(vk_surface);

    vkGetPhysicalDeviceSurfaceCapabilitiesKHR(device, vk_surface->get(), &details.capabilities_);

    uint32_t format_count;
    vkGetPhysicalDeviceSurfaceFormatsKHR(device, vk_surface->get(), &format_count, nullptr);

    if (format_count != 0) {
        details.formats_.resize(format_count);
        vkGetPhysicalDeviceSurfaceFormatsKHR(device, vk_surface->get(), &format_count, details.formats_.data());
    }

    uint32_t present_mode_count;
    vkGetPhysicalDeviceSurfacePresentModesKHR(device, vk_surface->get(), &present_mode_count, nullptr);

    if (present_mode_count != 0) {
        details.present_modes_.resize(present_mode_count);
        vkGetPhysicalDeviceSurfacePresentModesKHR(device, vk_surface->get(), &present_mode_count, details.present_modes_.data());
    }

    return details;
}

bool isDeviceSuitable(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    const std::shared_ptr<renderer::Surface>& surface) {
    renderer::QueueFamilyIndices indices = findQueueFamilies(physical_device, surface);

    const auto& vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    auto device = vk_physical_device->get();

    bool extensions_supported = checkDeviceExtensionSupport(physical_device);

    bool swap_chain_adequate = false;
    if (extensions_supported) {
        SwapChainSupportDetails swapChainSupport = querySwapChainSupport(physical_device, surface);
        swap_chain_adequate = !swapChainSupport.formats_.empty() && !swapChainSupport.present_modes_.empty();
    }

    VkPhysicalDeviceFeatures supported_features;
    vkGetPhysicalDeviceFeatures(device, &supported_features);

    return indices.isComplete() && extensions_supported && swap_chain_adequate && supported_features.samplerAnisotropy;
}

std::shared_ptr<renderer::PhysicalDevice> pickPhysicalDevice(
    const renderer::PhysicalDeviceList& physical_devices,
    const std::shared_ptr<renderer::Surface>& surface) {
    
    std::shared_ptr<renderer::PhysicalDevice> picked_device;
#if 0
    // Use an ordered map to automatically sort candidates by increasing score
    std::multimap<int, VkPhysicalDevice> candidates;

    for (const auto& device : devices) {
        int score = rateDeviceSuitability(device);
        candidates.insert(std::make_pair(score, device));
    }

    // Check if the best candidate is suitable at all
    if (candidates.rbegin()->first > 0) {
        vk_physical_device_ = candidates.rbegin()->second;
    }
    else {
        throw std::runtime_error("failed to find a suitable GPU!");
    }
#else
    for (const auto& device : physical_devices) {
        if (isDeviceSuitable(device, surface)) {
            picked_device = device;
            break;
        }
    }

    if (picked_device == VK_NULL_HANDLE) {
        throw std::runtime_error("failed to find a suitable GPU!");
    }
#endif

    return picked_device;
}

std::shared_ptr<renderer::Device> createLogicalDevice(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    const std::shared_ptr<renderer::Surface>& surface,
    const renderer::QueueFamilyIndices& indices) {

    std::vector<VkDeviceQueueCreateInfo> queue_create_infos;
    std::set<uint32_t> unique_queue_families = { indices.graphics_family_.value(), indices.present_family_.value() };

    float queue_priority = 1.0f;
    for (uint32_t queue_family : unique_queue_families) {
        VkDeviceQueueCreateInfo queue_create_info{};
        queue_create_info.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
        queue_create_info.queueFamilyIndex = queue_family;
        queue_create_info.queueCount = 1;
        queue_create_info.pQueuePriorities = &queue_priority;
        queue_create_infos.push_back(queue_create_info);
    }

    VkPhysicalDeviceFeatures device_features{};
    device_features.samplerAnisotropy = VK_TRUE;

    VkDeviceCreateInfo create_info{};
    create_info.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;

    create_info.queueCreateInfoCount = static_cast<uint32_t>(queue_create_infos.size());
    create_info.pQueueCreateInfos = queue_create_infos.data();

    create_info.pEnabledFeatures = &device_features;

    create_info.enabledExtensionCount = 0;

    if (enable_validation_layers) {
        create_info.enabledLayerCount = static_cast<uint32_t>(validation_layers.size());
        create_info.ppEnabledLayerNames = validation_layers.data();
    }
    else {
        create_info.enabledLayerCount = 0;
    }

    create_info.enabledExtensionCount = static_cast<uint32_t>(device_extensions.size());
    create_info.ppEnabledExtensionNames = device_extensions.data();

    const auto& vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    VkDevice vk_device;
    if (vkCreateDevice(vk_physical_device->get(), &create_info, nullptr, &vk_device) != VK_SUCCESS) {
        throw std::runtime_error("failed to create logical device!");
    }

    auto vk_logic_device = std::make_shared<renderer::VulkanDevice>(physical_device, vk_device);
    return vk_logic_device;
}

int rateDeviceSuitability(const VkPhysicalDevice& device) {
    VkPhysicalDeviceProperties device_properties;
    VkPhysicalDeviceFeatures device_features;
    vkGetPhysicalDeviceProperties(device, &device_properties);
    vkGetPhysicalDeviceFeatures(device, &device_features);

    int score = 0;

    // Discrete GPUs have a significant performance advantage
    if (device_properties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU) {
        score += 1000;
    }

    // Maximum possible size of textures affects graphics quality
    score += device_properties.limits.maxImageDimension2D;
    max_vertex_input_attribute_offset = device_properties.limits.maxVertexInputAttributeOffset;

    // Application can't function without geometry shaders
    if (!device_features.geometryShader) {
        return 0;
    }

    return score;
}

VkSurfaceFormatKHR chooseSwapSurfaceFormat(const std::vector<VkSurfaceFormatKHR>& available_formats) {
    for (const auto& available_format : available_formats) {
        if (available_format.format == VK_FORMAT_B8G8R8A8_UNORM &&
            available_format.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR) {
            return available_format;
        }
    }

    return available_formats[0];
}

work::renderer::PresentMode chooseSwapPresentMode(const std::vector<VkPresentModeKHR>& availablePresentModes) {
    for (const auto& availablePresentMode : availablePresentModes) {
        if (availablePresentMode == VK_PRESENT_MODE_MAILBOX_KHR) {
            return work::renderer::PresentMode::MAILBOX_KHR;
        }
    }

    return work::renderer::PresentMode::FIFO_KHR;
}

VkExtent2D chooseSwapExtent(GLFWwindow* window, const VkSurfaceCapabilitiesKHR& capabilities) {
    if (capabilities.currentExtent.width != std::numeric_limits<uint32_t>::max()) {
        return capabilities.currentExtent;
    }
    else {
        int width, height;
        glfwGetFramebufferSize(window, &width, &height);
        VkExtent2D actualExtent = { static_cast<uint32_t>(width), static_cast<uint32_t>(height) };
        actualExtent.width = std::max(capabilities.minImageExtent.width, std::min(capabilities.maxImageExtent.width, actualExtent.width));
        actualExtent.height = std::max(capabilities.minImageExtent.height, std::min(capabilities.maxImageExtent.height, actualExtent.height));

        return actualExtent;
    }
}

renderer::Format findSupportedFormat(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    const std::vector<renderer::Format>& candidates,
    const VkImageTiling& tiling,
    const VkFormatFeatureFlags& features) {
    const auto& vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    for (auto format : candidates) {
        VkFormatProperties props;
        auto vk_format = toVkFormat(format);
        vkGetPhysicalDeviceFormatProperties(vk_physical_device->get(), vk_format, &props);
        if (tiling == VK_IMAGE_TILING_LINEAR && (props.linearTilingFeatures & features) == features) {
            return format;
        }
        else if (tiling == VK_IMAGE_TILING_OPTIMAL && (props.optimalTilingFeatures & features) == features) {
            return format;
        }
    }

    throw std::runtime_error("failed to find supported format!");
}

renderer::Format findDepthFormat(
    const std::shared_ptr<renderer::Device>& device) {
    auto vk_device = RENDER_TYPE_CAST(Device, device);
    return findSupportedFormat(vk_device->getPhysicalDevice(),
        { work::renderer::Format::D32_SFLOAT_S8_UINT,
          work::renderer::Format::D32_SFLOAT,
          work::renderer::Format::D24_UNORM_S8_UINT,
          work::renderer::Format::D16_UNORM_S8_UINT,
          work::renderer::Format::D16_UNORM },
        VK_IMAGE_TILING_OPTIMAL,
        VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT
    );
}

std::vector<VkPipelineShaderStageCreateInfo> getShaderStages(
    const std::vector<std::shared_ptr<renderer::ShaderModule>>& shader_modules) {
    std::vector<VkPipelineShaderStageCreateInfo> shader_stages(shader_modules.size());

    // todo.
    auto vk_vert_shader_module = RENDER_TYPE_CAST(ShaderModule, shader_modules[0]);
    shader_stages[0].sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
    shader_stages[0].stage = VK_SHADER_STAGE_VERTEX_BIT;
    shader_stages[0].module = vk_vert_shader_module->get();
    shader_stages[0].pName = "main";

    // todo.
    for (int i = 1; i < shader_modules.size(); i++) {
        auto vk_frag_shader_module = RENDER_TYPE_CAST(ShaderModule, shader_modules[i]);
        shader_stages[i].sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
        shader_stages[i].stage = VK_SHADER_STAGE_FRAGMENT_BIT;
        shader_stages[i].module = vk_frag_shader_module->get();
        shader_stages[i].pName = "main";
    }

    return std::move(shader_stages);
}

uint32_t findMemoryType(
    const std::shared_ptr<renderer::PhysicalDevice>& physical_device,
    uint32_t type_filter,
    VkMemoryPropertyFlags properties) {

    auto vk_physical_device = RENDER_TYPE_CAST(PhysicalDevice, physical_device);
    assert(vk_physical_device);
    VkPhysicalDeviceMemoryProperties mem_properties;
    vkGetPhysicalDeviceMemoryProperties(vk_physical_device->get(), &mem_properties);

    for (uint32_t i = 0; i < mem_properties.memoryTypeCount; i++) {
        if ((type_filter & (1 << i)) && (mem_properties.memoryTypes[i].propertyFlags & properties) == properties) {
            return i;
        }
    }

    throw std::runtime_error("failed to find suitable memory type!");
}

VkWriteDescriptorSet addDescriptWrite(
    const VkDescriptorSet& description_set,
    const VkDescriptorImageInfo& image_info,
    uint32_t binding,
    const VkDescriptorType& desc_type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER) {
    VkWriteDescriptorSet result = {};
    result.sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
    result.dstSet = description_set;
    result.dstBinding = binding;
    result.dstArrayElement = 0;
    result.descriptorType = desc_type;
    result.descriptorCount = 1;
    result.pImageInfo = &image_info;

    return result;
}

void create2DImage(
    const std::shared_ptr<renderer::Device>& device,
    glm::vec2 tex_size,
    const renderer::Format& format,
    const renderer::ImageTiling& tiling,
    const renderer::ImageUsageFlags& usage,
    const renderer::MemoryPropertyFlags& properties,
    std::shared_ptr<renderer::Image>& image,
    std::shared_ptr<renderer::DeviceMemory>& image_memory) {
    image = device->createImage(renderer::ImageType::TYPE_2D, glm::uvec3(tex_size, 1), format, usage, tiling, renderer::ImageLayout::UNDEFINED);
    auto mem_requirements = device->getImageMemoryRequirements(image);
    image_memory = device->allocateMemory(mem_requirements.size,
        mem_requirements.memory_type_bits,
        toVkMemoryPropertyFlags(properties));
    device->bindImageMemory(image, image_memory);
}

void copyBuffer(
    const renderer::DeviceInfo& device_info,
    const std::shared_ptr<renderer::Buffer>& src_buffer,
    const std::shared_ptr<renderer::Buffer>& dst_buffer,
    uint64_t buffer_size) {

    const auto& device = device_info.device;
    const auto& cmd_queue = device_info.cmd_queue;
    const auto& cmd_pool = device_info.cmd_pool;

    auto command_buffers = device->allocateCommandBuffers(cmd_pool, 1);
    if (command_buffers.size() > 0) {
        auto& cmd_buf = command_buffers[0];
        if (cmd_buf) {
            cmd_buf->beginCommandBuffer(SET_FLAG_BIT(CommandBufferUsage, ONE_TIME_SUBMIT_BIT));

            std::vector<renderer::BufferCopyInfo> copy_regions(1);
            copy_regions[0].src_offset = 0; // Optional
            copy_regions[0].dst_offset = 0; // Optional
            copy_regions[0].size = buffer_size;
            cmd_buf->copyBuffer(src_buffer, dst_buffer, copy_regions);

            cmd_buf->endCommandBuffer();
        }

        cmd_queue->submit(command_buffers);
        cmd_queue->waitIdle();
        device->freeCommandBuffers(cmd_pool, command_buffers);
    }
}

bool hasStencilComponent(const renderer::Format& format) {
    return format == renderer::Format::D32_SFLOAT_S8_UINT ||
        format == renderer::Format::D24_UNORM_S8_UINT ||
        format == renderer::Format::D16_UNORM_S8_UINT;
}

void transitionImageLayout(
    const renderer::DeviceInfo& device_info,
    const std::shared_ptr<renderer::Image>& image,
    const renderer::Format& format,
    const renderer::ImageLayout& old_layout,
    const renderer::ImageLayout& new_layout,
    uint32_t base_mip_idx = 0,
    uint32_t mip_count = 1,
    uint32_t base_layer = 0,
    uint32_t layer_count = 1) {

    const auto& device = device_info.device;
    const auto& cmd_queue = device_info.cmd_queue;
    const auto& cmd_pool = device_info.cmd_pool;
    assert(device);
    assert(cmd_queue);
    assert(cmd_pool);

    auto command_buffers = device_info.device->allocateCommandBuffers(cmd_pool, 1);
    if (command_buffers.size() > 0) {
        auto& cmd_buf = command_buffers[0];
        if (cmd_buf) {
            cmd_buf->beginCommandBuffer(SET_FLAG_BIT(CommandBufferUsage, ONE_TIME_SUBMIT_BIT));

            VkImageMemoryBarrier barrier{};
            barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
            barrier.oldLayout = toVkImageLayout(old_layout);
            barrier.newLayout = toVkImageLayout(new_layout);
            barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
            barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;

            // todo.
            auto vk_image = RENDER_TYPE_CAST(Image, image);
            barrier.image = vk_image->get();
            if (new_layout == renderer::ImageLayout::DEPTH_STENCIL_ATTACHMENT_OPTIMAL) {
                barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_DEPTH_BIT;

                if (hasStencilComponent(format)) {
                    barrier.subresourceRange.aspectMask |= VK_IMAGE_ASPECT_STENCIL_BIT;
                }
            }
            else {
                barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
            }
            barrier.subresourceRange.baseMipLevel = base_mip_idx;
            barrier.subresourceRange.levelCount = mip_count;
            barrier.subresourceRange.baseArrayLayer = base_layer;
            barrier.subresourceRange.layerCount = layer_count;
            VkPipelineStageFlags source_stage;
            VkPipelineStageFlags destination_stage;

            if (old_layout == renderer::ImageLayout::UNDEFINED &&
                new_layout == renderer::ImageLayout::TRANSFER_DST_OPTIMAL) {
                barrier.srcAccessMask = 0;
                barrier.dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;

                source_stage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
                destination_stage = VK_PIPELINE_STAGE_TRANSFER_BIT;
            }
            else if (old_layout == renderer::ImageLayout::TRANSFER_DST_OPTIMAL &&
                new_layout == renderer::ImageLayout::SHADER_READ_ONLY_OPTIMAL) {
                barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
                barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

                source_stage = VK_PIPELINE_STAGE_TRANSFER_BIT;
                destination_stage = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
            }
            else if (old_layout == renderer::ImageLayout::UNDEFINED &&
                new_layout == renderer::ImageLayout::DEPTH_STENCIL_ATTACHMENT_OPTIMAL) {
                barrier.srcAccessMask = 0;
                barrier.dstAccessMask = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT | VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;

                source_stage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
                destination_stage = VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
            }
            else {
                throw std::invalid_argument("unsupported layout transition!");
            }

            // todo.
            //cmd_buf->pipelineBarrier();
            auto vk_cmd_Buf = RENDER_TYPE_CAST(CommandBuffer, cmd_buf);
            assert(vk_cmd_Buf);
            vkCmdPipelineBarrier(
                vk_cmd_Buf->get(),
                source_stage, destination_stage,
                0,
                0, nullptr,
                0, nullptr,
                1, &barrier
            );

            cmd_buf->endCommandBuffer();
        }

        cmd_queue->submit(command_buffers);
        cmd_queue->waitIdle();
        device->freeCommandBuffers(cmd_pool, command_buffers);
    }
}

void copyBufferToImageWithMips(
    const renderer::DeviceInfo& device_info,
    const std::shared_ptr<renderer::Buffer>& buffer,
    const std::shared_ptr<renderer::Image>& image,
    const std::vector<renderer::BufferImageCopyInfo>& copy_regions) {
    const auto& device = device_info.device;
    const auto& cmd_queue = device_info.cmd_queue;
    const auto& cmd_pool = device_info.cmd_pool;

    auto command_buffers = device->allocateCommandBuffers(cmd_pool, 1);
    if (command_buffers.size() > 0) {
        auto& cmd_buf = command_buffers[0];
        if (cmd_buf) {
            cmd_buf->beginCommandBuffer(SET_FLAG_BIT(CommandBufferUsage, ONE_TIME_SUBMIT_BIT));
            cmd_buf->copyBufferToImage(buffer, image, copy_regions, renderer::ImageLayout::TRANSFER_DST_OPTIMAL);
            cmd_buf->endCommandBuffer();
        }

        cmd_queue->submit(command_buffers);
        cmd_queue->waitIdle();
        device->freeCommandBuffers(cmd_pool, command_buffers);
    }
}

void copyBufferToImage(
    const renderer::DeviceInfo& device_info,
    const std::shared_ptr<renderer::Buffer>& buffer,
    const std::shared_ptr<renderer::Image>& image,
    const glm::uvec2& tex_size) {
    std::vector<renderer::BufferImageCopyInfo> copy_regions(1);
    auto& region = copy_regions[0];
    region.buffer_offset = 0;
    region.buffer_row_length = 0;
    region.buffer_image_height = 0;

    region.image_subresource.aspect_mask = SET_FLAG_BIT(ImageAspect, COLOR_BIT);
    region.image_subresource.mip_level = 0;
    region.image_subresource.base_array_layer = 0;
    region.image_subresource.layer_count = 1;

    region.image_offset = glm::ivec3(0, 0, 0);
    region.image_extent = glm::uvec3(tex_size, 1);

    copyBufferToImageWithMips(device_info, buffer, image, copy_regions);
}

static void generateMipmapLevels(
    const std::shared_ptr<renderer::CommandBuffer>& cmd_buf,
    const std::shared_ptr<renderer::Image>& image,
    uint32_t mip_count,
    uint32_t width,
    uint32_t height,
    const renderer::ImageLayout& cur_image_layout)
{
    auto vk_cmd_buf = RENDER_TYPE_CAST(CommandBuffer, cmd_buf);
    auto vk_image = RENDER_TYPE_CAST(Image, image);

    renderer::ImageResourceInfo src_info = {
        cur_image_layout,
        SET_FLAG_BIT(Access, COLOR_ATTACHMENT_WRITE_BIT),
        SET_FLAG_BIT(PipelineStage, COLOR_ATTACHMENT_OUTPUT_BIT)};

    renderer::ImageResourceInfo src_as_transfer = {
        renderer::ImageLayout::TRANSFER_SRC_OPTIMAL,
        SET_FLAG_BIT(Access, TRANSFER_READ_BIT),
        SET_FLAG_BIT(PipelineStage, TRANSFER_BIT)};

    cmd_buf->addImageBarrier(
        image,
        src_info,
        src_as_transfer,
        0, 1, 0, 6);

    for (uint32_t i = 1; i < mip_count; i++)
    {
        VkImageBlit imageBlit{};

        // Source
        imageBlit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
        imageBlit.srcSubresource.layerCount = 6u;
        imageBlit.srcSubresource.mipLevel = i - 1;
        imageBlit.srcOffsets[1].x = int32_t(width >> (i - 1));
        imageBlit.srcOffsets[1].y = int32_t(height >> (i - 1));
        imageBlit.srcOffsets[1].z = 1;

        // Destination
        imageBlit.dstSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
        imageBlit.dstSubresource.layerCount = 6u;
        imageBlit.dstSubresource.mipLevel = i;
        imageBlit.dstOffsets[1].x = int32_t(width >> i);
        imageBlit.dstOffsets[1].y = int32_t(height >> i);
        imageBlit.dstOffsets[1].z = 1;

        renderer::ImageResourceInfo src_mip_info = { 
            renderer::ImageLayout::UNDEFINED,
            SET_FLAG_BIT(Access, COLOR_ATTACHMENT_WRITE_BIT),
            SET_FLAG_BIT(PipelineStage, COLOR_ATTACHMENT_OUTPUT_BIT)};

        renderer::ImageResourceInfo dst_transfer_info = {
            renderer::ImageLayout::TRANSFER_DST_OPTIMAL,
            SET_FLAG_BIT(Access, TRANSFER_WRITE_BIT),
            SET_FLAG_BIT(PipelineStage, TRANSFER_BIT)};

        cmd_buf->addImageBarrier(
            image,
            src_mip_info,
            dst_transfer_info,
            i, 1, 0, 6);

        vkCmdBlitImage(
            vk_cmd_buf->get(),
            vk_image->get(),
            VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
            vk_image->get(),
            VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
            1,
            &imageBlit,
            VK_FILTER_LINEAR);

        cmd_buf->addImageBarrier(
            image,
            dst_transfer_info,
            src_as_transfer,
            i, 1, 0, 6);
    }

    {
        cmd_buf->addImageBarrier(
            image,
            src_as_transfer,
            renderer::Helper::getImageAsShaderSampler(),
            0, mip_count, 0, 6);
    }
}

void create2x2Texture(
    const renderer::DeviceInfo& device_info,
    uint32_t color,
    work::renderer::TextureInfo& texture) {
    auto format = renderer::Format::R8G8B8A8_UNORM;
    uint32_t colors[4] = { color };
    renderer::Helper::create2DTextureImage(device_info, format, 2, 2, 4, colors, texture.image, texture.memory);
    texture.view = device_info.device->createImageView(
        texture.image,
        renderer::ImageViewType::VIEW_2D,
        format,
        SET_FLAG_BIT(ImageAspect, COLOR_BIT));
}

std::vector<VkPipelineShaderStageCreateInfo> getComputeShaderStages(
    const std::vector<std::shared_ptr<renderer::ShaderModule>>& shader_modules) {
    std::vector<VkPipelineShaderStageCreateInfo> shader_stages(shader_modules.size());

    // todo.
    for (int i = 0; i < shader_modules.size(); i++) {
        auto vk_comp_shader_module = RENDER_TYPE_CAST(ShaderModule, shader_modules[i]);
        shader_stages[i].sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
        shader_stages[i].stage = VK_SHADER_STAGE_COMPUTE_BIT;
        shader_stages[i].module = vk_comp_shader_module->get();
        shader_stages[i].pName = "main";
    }

    return std::move(shader_stages);
}

VkPipelineVertexInputStateCreateInfo fillVkPipelineVertexInputStateCreateInfo(
    const std::vector<VkVertexInputBindingDescription>& binding_descs,
    const std::vector<VkVertexInputAttributeDescription>& attribute_descs) {
    VkPipelineVertexInputStateCreateInfo vertex_input_info{};
    vertex_input_info.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
    vertex_input_info.vertexBindingDescriptionCount = static_cast<uint32_t>(binding_descs.size());
    vertex_input_info.pVertexBindingDescriptions = binding_descs.data();
    vertex_input_info.vertexAttributeDescriptionCount = static_cast<uint32_t>(attribute_descs.size());
    vertex_input_info.pVertexAttributeDescriptions = attribute_descs.data();

    return vertex_input_info;
}

VkPipelineInputAssemblyStateCreateInfo fillVkPipelineInputAssemblyStateCreateInfo(
    const renderer::PipelineInputAssemblyStateCreateInfo& topology_info) {
    VkPipelineInputAssemblyStateCreateInfo input_assembly{};
    input_assembly.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
    input_assembly.topology = toVkPrimitiveTopology(topology_info.topology);
    input_assembly.primitiveRestartEnable = topology_info.restart_enable;

    return input_assembly;
}

std::vector<VkPipelineColorBlendAttachmentState> fillVkPipelineColorBlendAttachments(
    const renderer::PipelineColorBlendStateCreateInfo& blend_info) {
    std::vector<VkPipelineColorBlendAttachmentState> attachments(blend_info.attachment_count);
    for (uint32_t i = 0; i < blend_info.attachment_count; i++) {
        auto& src_att = blend_info.attachments[i];
        attachments[i].blendEnable = src_att.blend_enable ? VK_TRUE : VK_FALSE;
        attachments[i].srcColorBlendFactor = toVkBlendFactor(src_att.src_color_blend_factor);
        attachments[i].dstColorBlendFactor = toVkBlendFactor(src_att.dst_color_blend_factor);
        attachments[i].colorBlendOp = toVkBlendOp(src_att.color_blend_op);
        attachments[i].srcAlphaBlendFactor = toVkBlendFactor(src_att.src_alpha_blend_factor);
        attachments[i].dstAlphaBlendFactor = toVkBlendFactor(src_att.dst_alpha_blend_factor);
        attachments[i].alphaBlendOp = toVkBlendOp(src_att.alpha_blend_op);
        attachments[i].colorWriteMask = toVkColorComponentFlags(src_att.color_write_mask);
    }

    return attachments;
}

VkPipelineColorBlendStateCreateInfo fillVkPipelineColorBlendStateCreateInfo(
    const renderer::PipelineColorBlendStateCreateInfo& blend_info,
    const std::vector<VkPipelineColorBlendAttachmentState>& attachments) {
    VkPipelineColorBlendStateCreateInfo color_blending{};
    color_blending.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
    color_blending.logicOpEnable = blend_info.logic_op_enable ? VK_TRUE : VK_FALSE;
    color_blending.logicOp = toVkLogicOp(blend_info.logic_op);
    color_blending.attachmentCount = static_cast<uint32_t>(attachments.size());
    color_blending.pAttachments = attachments.data();
    color_blending.blendConstants[0] = blend_info.blend_constants.x;
    color_blending.blendConstants[1] = blend_info.blend_constants.y;
    color_blending.blendConstants[2] = blend_info.blend_constants.z;
    color_blending.blendConstants[3] = blend_info.blend_constants.w;

    return color_blending;
}

VkPipelineRasterizationStateCreateInfo fillVkPipelineRasterizationStateCreateInfo(
    const renderer::PipelineRasterizationStateCreateInfo& rasterization_info) {
    VkPipelineRasterizationStateCreateInfo rasterizer{};
    rasterizer.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
    rasterizer.depthClampEnable = rasterization_info.depth_clamp_enable ? VK_TRUE : VK_FALSE;
    rasterizer.rasterizerDiscardEnable = rasterization_info.rasterizer_discard_enable ? VK_TRUE : VK_FALSE;
    rasterizer.polygonMode = toVkPolygonMode(rasterization_info.polygon_mode);
    rasterizer.lineWidth = rasterization_info.line_width;
    rasterizer.cullMode = toVkCullModeFlags(rasterization_info.cull_mode);
    rasterizer.frontFace = toVkFrontFace(rasterization_info.front_face);
    rasterizer.depthBiasEnable = rasterization_info.depth_bias_enable ? VK_TRUE : VK_FALSE;
    rasterizer.depthBiasConstantFactor = rasterization_info.depth_bias_constant_factor; // Optional
    rasterizer.depthBiasClamp = rasterization_info.depth_bias_clamp; // Optional
    rasterizer.depthBiasSlopeFactor = rasterization_info.depth_bias_slope_factor; // Optional

    return rasterizer;
}

VkPipelineMultisampleStateCreateInfo fillVkPipelineMultisampleStateCreateInfo(
    const renderer::PipelineMultisampleStateCreateInfo& ms_info) {
    VkPipelineMultisampleStateCreateInfo multisampling{};
    multisampling.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
    multisampling.sampleShadingEnable = ms_info.sample_shading_enable ? VK_TRUE : VK_FALSE;
    multisampling.rasterizationSamples = static_cast<VkSampleCountFlagBits>(toVkSampleCountFlags(static_cast<renderer::SampleCountFlags>(ms_info.rasterization_samples)));
    multisampling.minSampleShading = ms_info.min_sample_shading; // Optional
    multisampling.pSampleMask = ms_info.sample_mask; // Optional
    multisampling.alphaToCoverageEnable = ms_info.alpha_to_coverage_enable ? VK_TRUE : VK_FALSE; // Optional
    multisampling.alphaToOneEnable = ms_info.alpha_to_one_enable ? VK_TRUE : VK_FALSE; // Optional

    return multisampling;
}

VkViewport fillViewport(const glm::uvec2 size) {
    VkViewport viewport{};
    viewport.x = 0.0f;
    viewport.y = 0.0f;
    viewport.width = (float)size.x;
    viewport.height = (float)size.y;
    viewport.minDepth = 0.0f;
    viewport.maxDepth = 1.0f;

    return viewport;
}

VkRect2D fillScissor(const glm::uvec2 size) {
    VkRect2D scissor{};
    scissor.offset = { 0, 0 };
    scissor.extent = { size.x, size.y };

    return scissor;
}

VkPipelineViewportStateCreateInfo fillVkPipelineViewportStateCreateInfo(const VkViewport* viewport, const VkRect2D* scissor) {
    VkPipelineViewportStateCreateInfo viewport_state{};
    viewport_state.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
    viewport_state.viewportCount = 1;
    viewport_state.pViewports = viewport;
    viewport_state.scissorCount = 1;
    viewport_state.pScissors = scissor;

    return viewport_state;
}

std::vector<VkPipelineColorBlendAttachmentState> fillVkPipelineColorBlendAttachmentState(uint32_t num_attachments) {
    std::vector<VkPipelineColorBlendAttachmentState> color_blend_attachements(num_attachments);
    VkPipelineColorBlendAttachmentState color_blend_attachment{};
    color_blend_attachment.colorWriteMask = VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;
    color_blend_attachment.blendEnable = VK_FALSE;
    color_blend_attachment.srcColorBlendFactor = VK_BLEND_FACTOR_ONE; // Optional
    color_blend_attachment.dstColorBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional
    color_blend_attachment.colorBlendOp = VK_BLEND_OP_ADD; // Optional
    color_blend_attachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE; // Optional
    color_blend_attachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional
    color_blend_attachment.alphaBlendOp = VK_BLEND_OP_ADD; // Optional

    for (uint32_t i = 0; i < num_attachments; i++) {
        color_blend_attachements[i] = color_blend_attachment;
    }

    return std::move(color_blend_attachements);
}

VkStencilOpState fillVkStencilOpState(const renderer::StencilOpState& stencil_op) {
    VkStencilOpState vk_stencil_op{};
    vk_stencil_op.failOp = toVkStencilOp(stencil_op.fail_op);
    vk_stencil_op.passOp = toVkStencilOp(stencil_op.pass_op);
    vk_stencil_op.depthFailOp = toVkStencilOp(stencil_op.depth_fail_op);
    vk_stencil_op.compareOp = toVkCompareOp(stencil_op.compare_op);
    vk_stencil_op.compareMask = stencil_op.compare_mask;
    vk_stencil_op.writeMask = stencil_op.write_mask;
    vk_stencil_op.reference = stencil_op.reference;
    return vk_stencil_op;
}

VkPipelineDepthStencilStateCreateInfo fillVkPipelineDepthStencilStateCreateInfo(
    const renderer::PipelineDepthStencilStateCreateInfo& depth_stencil_info) {
    VkPipelineDepthStencilStateCreateInfo depth_stencil{};
    depth_stencil.sType = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO;
    depth_stencil.depthTestEnable = depth_stencil_info.depth_test_enable ? VK_TRUE : VK_FALSE;
    depth_stencil.depthWriteEnable = depth_stencil_info.depth_write_enable ? VK_TRUE : VK_FALSE;
    depth_stencil.depthCompareOp = toVkCompareOp(depth_stencil_info.depth_compare_op);
    depth_stencil.depthBoundsTestEnable = depth_stencil_info.depth_bounds_test_enable ? VK_TRUE : VK_FALSE;
    depth_stencil.minDepthBounds = depth_stencil_info.min_depth_bounds; // Optional
    depth_stencil.maxDepthBounds = depth_stencil_info.max_depth_bounds; // Optional
    depth_stencil.stencilTestEnable = depth_stencil_info.stencil_test_enable ? VK_TRUE : VK_FALSE;
    depth_stencil.front = fillVkStencilOpState(depth_stencil_info.front); // Optional
    depth_stencil.back = fillVkStencilOpState(depth_stencil_info.back); // Optional

    return depth_stencil;
}

VkAttachmentDescription FillVkAttachmentDescription(
    const renderer::AttachmentDescription& attachment_desc) {
    VkAttachmentDescription attachment{};
    attachment.format = toVkFormat(attachment_desc.format);
    attachment.samples = static_cast<VkSampleCountFlagBits>(toVkSampleCountFlags(static_cast<renderer::SampleCountFlags>(attachment_desc.samples)));
    attachment.initialLayout = toVkImageLayout(attachment_desc.initial_layout);
    attachment.finalLayout = toVkImageLayout(attachment_desc.final_layout);
    attachment.loadOp = VkAttachmentLoadOp(attachment_desc.load_op);
    attachment.storeOp = VkAttachmentStoreOp(attachment_desc.store_op);
    attachment.stencilLoadOp = VkAttachmentLoadOp(attachment_desc.stencil_load_op);
    attachment.stencilStoreOp = VkAttachmentStoreOp(attachment_desc.stencil_store_op);

    return attachment;
}

std::vector<VkAttachmentReference> FillVkAttachmentReference(
    const std::vector<renderer::AttachmentReference>& attachment_references) {
    const size_t& num_atts = attachment_references.size();
    std::vector<VkAttachmentReference> vk_attachment_references(num_atts);
    for (auto i = 0; i < num_atts; i++) {
        vk_attachment_references[i].attachment = attachment_references[i].attachment_;
        vk_attachment_references[i].layout = toVkImageLayout(attachment_references[i].layout_);
    }
    return vk_attachment_references;
}

struct SubpassAttachments {
    std::vector<VkAttachmentReference> input_attachments;
    std::vector<VkAttachmentReference> color_attachments;
    std::vector<VkAttachmentReference> resolve_attachments;
    std::vector<VkAttachmentReference> depth_stencil_attachment;
};
VkSubpassDescription FillVkSubpassDescription(
    const renderer::SubpassDescription& subpass,
    const SubpassAttachments& attachments) {
    VkSubpassDescription vk_desc{};
    vk_desc.flags = toVkSubpassDescriptionFlags(subpass.flags);
    vk_desc.pipelineBindPoint = toVkPipelineBindPoint(subpass.pipeline_bind_point);
    vk_desc.inputAttachmentCount = static_cast<uint32_t>(attachments.input_attachments.size());
    vk_desc.pInputAttachments = vk_desc.inputAttachmentCount > 0 ? attachments.input_attachments.data() : nullptr;
    vk_desc.colorAttachmentCount = static_cast<uint32_t>(attachments.color_attachments.size());
    vk_desc.pColorAttachments = vk_desc.colorAttachmentCount > 0 ? attachments.color_attachments.data() : nullptr;
    vk_desc.pResolveAttachments = attachments.resolve_attachments.size() > 0 ? attachments.resolve_attachments.data() : nullptr;
    vk_desc.pDepthStencilAttachment = attachments.depth_stencil_attachment.size() > 0 ? attachments.depth_stencil_attachment.data() : nullptr;
    return vk_desc;
}

VkSubpassDependency FillVkSubpassDependency(const renderer::SubpassDependency& dependency) {
    VkSubpassDependency vk_dependency{};
    vk_dependency.srcSubpass = dependency.src_subpass;
    vk_dependency.dstSubpass = dependency.dst_subpass;
    vk_dependency.srcStageMask = toVkPipelineStageFlags(dependency.src_stage_mask);
    vk_dependency.dstStageMask = toVkPipelineStageFlags(dependency.dst_stage_mask);
    vk_dependency.srcAccessMask = toVkAccessFlags(dependency.src_access_mask);
    vk_dependency.dstAccessMask = toVkAccessFlags(dependency.dst_access_mask);
    vk_dependency.dependencyFlags = toVkDependencyFlags(dependency.dependency_flags);
    return vk_dependency;
}

}

namespace renderer {

std::shared_ptr<Buffer> VulkanDevice::createBuffer(uint64_t buf_size, BufferUsageFlags usage, bool sharing/* = false*/) {
    VkBufferCreateInfo buffer_info{};
    buffer_info.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
    buffer_info.size = buf_size;
    buffer_info.usage = toVkBufferUsageFlags(usage);
    buffer_info.sharingMode = sharing ? VK_SHARING_MODE_CONCURRENT : VK_SHARING_MODE_EXCLUSIVE;

    VkBuffer buffer;
    if (vkCreateBuffer(device_, &buffer_info, nullptr, &buffer) != VK_SUCCESS) {
        throw std::runtime_error("failed to create buffer!");
    }

    auto result = std::make_shared<VulkanBuffer>();
    result->set(buffer);

    return result;
}

void VulkanDevice::createBuffer(
    const uint64_t& buffer_size,
    const BufferUsageFlags& usage,
    const MemoryPropertyFlags& properties,
    std::shared_ptr<Buffer>& buffer,
    std::shared_ptr<DeviceMemory>& buffer_memory) {
    buffer = createBuffer(buffer_size, usage);
    auto mem_requirements = getBufferMemoryRequirements(buffer);
    buffer_memory = allocateMemory(mem_requirements.size,
        mem_requirements.memory_type_bits,
        toVkMemoryPropertyFlags(properties));
    bindBufferMemory(buffer, buffer_memory);
}

std::shared_ptr<Image> VulkanDevice::createImage(
    ImageType image_type,
    glm::uvec3 image_size,
    Format format,
    ImageUsageFlags usage,
    ImageTiling tiling,
    ImageLayout layout,
    ImageCreateFlags flags/* = 0*/,
    bool sharing/* = false*/,
    uint32_t num_samples/* = 1*/,
    uint32_t num_mips/* = 1*/,
    uint32_t num_layers/* = 1*/) {
    VkImageCreateInfo image_info{};
    image_info.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
    image_info.imageType = toVkImageType(image_type);
    image_info.extent.width = image_size.x;
    image_info.extent.height = image_size.y;
    image_info.extent.depth = image_size.z;
    image_info.mipLevels = num_mips;
    image_info.arrayLayers = num_layers;
    image_info.format = toVkFormat(format);
    image_info.tiling = toVkImageTiling(tiling);
    image_info.initialLayout = toVkImageLayout(layout);
    image_info.usage = toVkImageUsageFlags(usage);
    image_info.sharingMode = sharing ? VK_SHARING_MODE_CONCURRENT : VK_SHARING_MODE_EXCLUSIVE;
    image_info.samples = static_cast<VkSampleCountFlagBits>(num_samples);
    image_info.flags = toVkImageCreateFlags(flags);

    VkImage image;
    if (vkCreateImage(device_, &image_info, nullptr, &image) != VK_SUCCESS) {
        throw std::runtime_error("failed to create image!");
    }

    auto result = std::make_shared<VulkanImage>();
    result->set(image);
    return result;
}

std::shared_ptr<ImageView> VulkanDevice::createImageView(
    std::shared_ptr<Image> image,
    ImageViewType view_type,
    Format format,
    ImageAspectFlags aspect_flags,
    uint32_t base_mip/* = 0*/,
    uint32_t mip_count/* = 1*/,
    uint32_t base_layer/* = 0*/,
    uint32_t layer_count/* = 1*/) {
    auto vk_image = RENDER_TYPE_CAST(Image, image);

    VkImageViewCreateInfo view_info{};
    view_info.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
    view_info.image = vk_image->get();
    view_info.viewType = toVkImageViewType(view_type);
    view_info.format = toVkFormat(format);
    view_info.subresourceRange.aspectMask = toVkImageAspectFlags(aspect_flags);
    view_info.subresourceRange.baseMipLevel = base_mip;
    view_info.subresourceRange.levelCount = mip_count;
    view_info.subresourceRange.baseArrayLayer = base_layer;
    view_info.subresourceRange.layerCount = layer_count;

    VkImageView image_view;
    if (vkCreateImageView(device_, &view_info, nullptr, &image_view) != VK_SUCCESS) {
        throw std::runtime_error("failed to create texture image view!");
    }

    auto result = std::make_shared<VulkanImageView>();
    result->set(image_view);

    return result;
}

std::shared_ptr<Sampler> VulkanDevice::createSampler(Filter filter, SamplerAddressMode address_mode, SamplerMipmapMode mipmap_mode, float anisotropy) {
    auto vk_filter = toVkFilter(filter);
    auto vk_address_mode = toVkSamplerAddressMode(address_mode);
    auto vk_mipmap_mode = toVkSamplerMipmapMode(mipmap_mode);

    VkSamplerCreateInfo sampler_info{};
    sampler_info.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
    sampler_info.magFilter = vk_filter;
    sampler_info.minFilter = vk_filter;
    sampler_info.addressModeU = vk_address_mode;
    sampler_info.addressModeV = vk_address_mode;
    sampler_info.addressModeW = vk_address_mode;
    sampler_info.anisotropyEnable = anisotropy > 0 ? VK_TRUE : VK_FALSE;
    sampler_info.maxAnisotropy = anisotropy;
    sampler_info.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;
    sampler_info.unnormalizedCoordinates = VK_FALSE;
    sampler_info.compareEnable = VK_FALSE;
    sampler_info.compareOp = VK_COMPARE_OP_ALWAYS;
    sampler_info.mipmapMode = vk_mipmap_mode;
    sampler_info.mipLodBias = 0.0f;
    sampler_info.minLod = 0.0f;
    sampler_info.maxLod = 1024.0f;

    VkSampler tex_sampler;
    if (vkCreateSampler(device_, &sampler_info, nullptr, &tex_sampler) != VK_SUCCESS) {
        throw std::runtime_error("failed to create texture sampler!");
    }

    auto vk_tex_sampler = std::make_shared<VulkanSampler>();
    vk_tex_sampler->set(tex_sampler);
    return vk_tex_sampler;
}

std::shared_ptr<Semaphore> VulkanDevice::createSemaphore() {
    VkSemaphoreCreateInfo semaphore_info{};
    semaphore_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;

    VkSemaphore semaphore;
    if (vkCreateSemaphore(device_, &semaphore_info, nullptr, &semaphore) != VK_SUCCESS) {
        throw std::runtime_error("failed to create semaphore!");
    }

    auto vk_semaphore = std::make_shared<VulkanSemaphore>();
    vk_semaphore->set(semaphore);
    return vk_semaphore;
}

std::shared_ptr<Fence> VulkanDevice::createFence() {
    VkFenceCreateInfo fence_info{};
    fence_info.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;
    fence_info.flags = VK_FENCE_CREATE_SIGNALED_BIT;

    VkFence fence;
    if (vkCreateFence(device_, &fence_info, nullptr, &fence) != VK_SUCCESS) {
        throw std::runtime_error("failed to create fence!");
    }

    auto vk_fence = std::make_shared<VulkanFence>();
    vk_fence->set(fence);
    return vk_fence;
}

std::shared_ptr<ShaderModule> VulkanDevice::createShaderModule(uint64_t size, void* data) {
    VkShaderModuleCreateInfo create_info{};
    create_info.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
    create_info.codeSize = size;
    create_info.pCode = reinterpret_cast<const uint32_t*>(data);

    VkShaderModule shader_module;
    if (vkCreateShaderModule(device_, &create_info, nullptr, &shader_module) != VK_SUCCESS) {
        throw std::runtime_error("failed to create shader module!");
    }

    auto vk_shader_module = std::make_shared<VulkanShaderModule>();
    vk_shader_module->set(shader_module);

    return vk_shader_module;
}

std::shared_ptr<CommandPool> VulkanDevice::createCommandPool(uint32_t queue_family_index, CommandPoolCreateFlags flags) {
    VkCommandPoolCreateInfo pool_info{};
    pool_info.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
    pool_info.queueFamilyIndex = queue_family_index;
    pool_info.flags = toVkCommandPoolCreateFlags(flags);

    VkCommandPool cmd_pool;
    if (vkCreateCommandPool(device_, &pool_info, nullptr, &cmd_pool) != VK_SUCCESS) {
        throw std::runtime_error("failed to create command pool!");
    }

    auto vk_cmd_pool = std::make_shared<VulkanCommandPool>();
    vk_cmd_pool->set(cmd_pool);
    return vk_cmd_pool;
}

std::shared_ptr<Queue> VulkanDevice::getDeviceQueue(uint32_t queue_family_index, uint32_t queue_index/* = 0*/) {
    VkQueue queue;
    vkGetDeviceQueue(device_, queue_family_index, queue_index, &queue);
    auto vk_queue = std::make_shared<VulkanQueue>();
    vk_queue->set(queue);
    return vk_queue;
}

std::shared_ptr<DescriptorSetLayout> VulkanDevice::createDescriptorSetLayout(
    const std::vector<DescriptorSetLayoutBinding>& bindings) {
    std::vector<VkDescriptorSetLayoutBinding> vk_bindings(bindings.size());
    for (auto i = 0; i < bindings.size(); i++) {
        const auto& binding = bindings[i];
        auto& vk_binding = vk_bindings[i];
        vk_binding.binding = binding.binding;
        vk_binding.descriptorType = toVkDescriptorType(binding.descriptor_type);
        vk_binding.descriptorCount = binding.descriptor_count;
        vk_binding.stageFlags = toVkShaderStageFlags(binding.stage_flags);
        auto vk_samplers = RENDER_TYPE_CAST(Sampler, binding.immutable_samplers);
        vk_binding.pImmutableSamplers = vk_samplers ? vk_samplers->getPtr() : nullptr;
    }

    VkDescriptorSetLayoutCreateInfo layout_info{};
    layout_info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
    layout_info.bindingCount = static_cast<uint32_t>(vk_bindings.size());
    layout_info.pBindings = vk_bindings.data();

    VkDescriptorSetLayout descriptor_set_layout;
    if (vkCreateDescriptorSetLayout(device_, &layout_info, nullptr, &descriptor_set_layout) != VK_SUCCESS) {
        throw std::runtime_error("failed to create descriptor set layout!");
    }

    auto vk_set_layout = std::make_shared<VulkanDescriptorSetLayout>();
    vk_set_layout->set(descriptor_set_layout);
    return vk_set_layout;
}

std::shared_ptr<RenderPass> VulkanDevice::createRenderPass(
    const std::vector<AttachmentDescription>& attachments,
    const std::vector<SubpassDescription>& subpasses,
    const std::vector<SubpassDependency>& dependencies) {

    std::vector<VkAttachmentDescription> vk_attachments(attachments.size());
    for (int i = 0; i < attachments.size(); i++) {
        vk_attachments[i] = FillVkAttachmentDescription(attachments[i]);
    }

    std::vector<SubpassAttachments> subpass_attachments(subpasses.size());
    for (uint32_t i = 0; i < subpasses.size(); i++) {
        subpass_attachments[i].input_attachments = FillVkAttachmentReference(subpasses[i].input_attachments);
        subpass_attachments[i].color_attachments = FillVkAttachmentReference(subpasses[i].color_attachments);
        subpass_attachments[i].resolve_attachments = FillVkAttachmentReference(subpasses[i].resolve_attachments);
        subpass_attachments[i].depth_stencil_attachment = FillVkAttachmentReference(subpasses[i].depth_stencil_attachment);
    }

    std::vector<VkSubpassDescription> vk_subpasses(subpasses.size());
    for (int i = 0; i < subpasses.size(); i++) {
        vk_subpasses[i] = FillVkSubpassDescription(subpasses[i], subpass_attachments[i]);
    }

    std::vector<VkSubpassDependency> vk_dependencies(dependencies.size());
    for (int i = 0; i < dependencies.size(); i++) {
        vk_dependencies[i] = FillVkSubpassDependency(dependencies[i]);
    }

    VkRenderPassCreateInfo render_pass_info{};
    render_pass_info.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
    render_pass_info.attachmentCount = static_cast<uint32_t>(vk_attachments.size());
    render_pass_info.pAttachments = vk_attachments.data();
    render_pass_info.subpassCount = static_cast<uint32_t>(vk_subpasses.size());
    render_pass_info.pSubpasses = vk_subpasses.data();
    render_pass_info.dependencyCount = static_cast<uint32_t>(vk_dependencies.size());
    render_pass_info.pDependencies = vk_dependencies.data();

    VkRenderPass render_pass;
    if (vkCreateRenderPass(device_, &render_pass_info, nullptr, &render_pass) != VK_SUCCESS) {
        throw std::runtime_error("failed to create render pass!");
    }

    auto vk_render_pass = std::make_shared<VulkanRenderPass>();
    vk_render_pass->set(render_pass);
    return vk_render_pass;
}

DescriptorSetList VulkanDevice::createDescriptorSets(
    std::shared_ptr<DescriptorPool> descriptor_pool,
    std::shared_ptr<DescriptorSetLayout> descriptor_set_layout,
    uint64_t buffer_count) {
    auto vk_descriptor_pool = RENDER_TYPE_CAST(DescriptorPool, descriptor_pool);
    auto vk_descriptor_set_layout = RENDER_TYPE_CAST(DescriptorSetLayout, descriptor_set_layout);
    std::vector<VkDescriptorSetLayout> layouts(buffer_count, vk_descriptor_set_layout->get());
    VkDescriptorSetAllocateInfo alloc_info{};
    alloc_info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
    alloc_info.descriptorPool = vk_descriptor_pool->get();
    alloc_info.descriptorSetCount = static_cast<uint32_t>(buffer_count);
    alloc_info.pSetLayouts = layouts.data();

    std::vector<VkDescriptorSet> vk_desc_sets;
    vk_desc_sets.resize(buffer_count);
    if (vkAllocateDescriptorSets(device_, &alloc_info, vk_desc_sets.data()) != VK_SUCCESS) {
        throw std::runtime_error("failed to allocate descriptor sets!");
    }

    DescriptorSetList desc_sets(vk_desc_sets.size());
    for (uint32_t i = 0; i < buffer_count; i++) {
        auto vk_desc_set = std::make_shared<VulkanDescriptorSet>();
        vk_desc_set->set(vk_desc_sets[i]);
        desc_sets[i] = vk_desc_set;
    }

    return std::move(desc_sets);
}

std::shared_ptr<PipelineLayout> VulkanDevice::createPipelineLayout(
    const DescriptorSetLayoutList& desc_set_layouts,
    const std::vector<PushConstantRange>& push_const_ranges) {

    std::vector<VkPushConstantRange> vk_push_const_ranges;
    vk_push_const_ranges.reserve(push_const_ranges.size());
    for (auto& push_const_range : push_const_ranges) {
        VkPushConstantRange vk_push_const_range{};
        vk_push_const_range.stageFlags = toVkShaderStageFlags(push_const_range.stage_flags);
        vk_push_const_range.offset = push_const_range.offset;
        vk_push_const_range.size = push_const_range.size;
        vk_push_const_ranges.push_back(vk_push_const_range);
    }

    VkPipelineLayoutCreateInfo pipeline_layout_info{};
    pipeline_layout_info.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;
    // todo.
    std::vector<VkDescriptorSetLayout> vk_layouts;
    vk_layouts.reserve(desc_set_layouts.size());
    for (auto& desc_set_layout : desc_set_layouts) {
        vk_layouts.push_back(RENDER_TYPE_CAST(DescriptorSetLayout, desc_set_layout)->get());
    }

    pipeline_layout_info.setLayoutCount = static_cast<uint32_t>(vk_layouts.size());
    pipeline_layout_info.pSetLayouts = vk_layouts.data();
    pipeline_layout_info.pushConstantRangeCount = static_cast<uint32_t>(vk_push_const_ranges.size());
    pipeline_layout_info.pPushConstantRanges = vk_push_const_ranges.data();

    VkPipelineLayout pipeline_layout;
    if (vkCreatePipelineLayout(device_, &pipeline_layout_info, nullptr, &pipeline_layout) != VK_SUCCESS) {
        throw std::runtime_error("failed to create pipeline layout!");
    }
    auto vk_pipeline_layout = std::make_shared<VulkanPipelineLayout>();
    vk_pipeline_layout->set(pipeline_layout);

    return vk_pipeline_layout;
}

std::shared_ptr<Pipeline> VulkanDevice::createPipeline(
    const std::shared_ptr<RenderPass>& render_pass,
    const std::shared_ptr<PipelineLayout>& pipeline_layout,
    const std::vector<VertexInputBindingDescription>& binding_descs,
    const std::vector<VertexInputAttributeDescription>& attribute_descs,
    const PipelineInputAssemblyStateCreateInfo& topology_info,
    const PipelineColorBlendStateCreateInfo& blend_state_info,
    const PipelineRasterizationStateCreateInfo& rasterization_info,
    const PipelineMultisampleStateCreateInfo& ms_info,
    const PipelineDepthStencilStateCreateInfo& depth_stencil_info,
    const ShaderModuleList& shader_modules,
    const glm::uvec2& extent) {

    VkGraphicsPipelineCreateInfo pipeline_info{};

    auto viewport = fillViewport(extent);
    auto scissor = fillScissor(extent);

    auto vk_blend_attachments = fillVkPipelineColorBlendAttachments(blend_state_info);
    auto vk_color_blending = fillVkPipelineColorBlendStateCreateInfo(blend_state_info, vk_blend_attachments);
    auto vk_rasterizer = fillVkPipelineRasterizationStateCreateInfo(rasterization_info);
    auto vk_multisampling = fillVkPipelineMultisampleStateCreateInfo(ms_info);
    auto vk_depth_stencil = fillVkPipelineDepthStencilStateCreateInfo(depth_stencil_info);

    auto viewport_state = fillVkPipelineViewportStateCreateInfo(&viewport, &scissor);

    auto vk_binding_descs = toVkVertexInputBindingDescription(binding_descs);
    auto vk_attribute_descs = toVkVertexInputAttributeDescription(attribute_descs);
    auto vk_vertex_input_info = fillVkPipelineVertexInputStateCreateInfo(vk_binding_descs, vk_attribute_descs);
    auto vk_input_assembly = fillVkPipelineInputAssemblyStateCreateInfo(topology_info);
    auto shader_stages = getShaderStages(shader_modules);

    auto vk_pipeline_layout = RENDER_TYPE_CAST(PipelineLayout, pipeline_layout);
    assert(vk_pipeline_layout);

    auto vk_render_pass = RENDER_TYPE_CAST(RenderPass, render_pass);
    assert(vk_render_pass);

    pipeline_info.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;
    pipeline_info.stageCount = static_cast<uint32_t>(shader_stages.size());
    pipeline_info.pStages = shader_stages.data();
    pipeline_info.pVertexInputState = &vk_vertex_input_info;
    pipeline_info.pInputAssemblyState = &vk_input_assembly;
    pipeline_info.pViewportState = &viewport_state;
    pipeline_info.pRasterizationState = &vk_rasterizer;
    pipeline_info.pMultisampleState = &vk_multisampling;
    pipeline_info.pDepthStencilState = &vk_depth_stencil;
    pipeline_info.pColorBlendState = &vk_color_blending;
    //    pipeline_info.pDynamicState = nullptr; // Optional
    pipeline_info.layout = vk_pipeline_layout->get();
    pipeline_info.renderPass = vk_render_pass->get();
    pipeline_info.subpass = 0;
    pipeline_info.basePipelineHandle = VK_NULL_HANDLE; // Optional
    pipeline_info.basePipelineIndex = -1; // Optional

    VkPipeline graphics_pipeline;
    if (vkCreateGraphicsPipelines(device_, VK_NULL_HANDLE, 1, &pipeline_info, nullptr, &graphics_pipeline) != VK_SUCCESS) {
        throw std::runtime_error("failed to create graphics pipeline!");
    }
    auto vk_pipeline = std::make_shared<VulkanPipeline>();
    vk_pipeline->set(graphics_pipeline);
    return vk_pipeline;
}

std::shared_ptr<Pipeline> VulkanDevice::createPipeline(
    const std::shared_ptr<PipelineLayout>& pipeline_layout,
    const std::shared_ptr<ShaderModule>& shader_module) {
    auto ibl_compute_shader_stages = getComputeShaderStages({ shader_module });

    auto vk_ibl_comp_pipeline_layout = RENDER_TYPE_CAST(PipelineLayout, pipeline_layout);
    assert(vk_ibl_comp_pipeline_layout);

    // flags = 0, - e.g. disable optimization
    VkComputePipelineCreateInfo pipeline_info = {};
    pipeline_info.sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO;
    pipeline_info.stage = ibl_compute_shader_stages[0];
    pipeline_info.basePipelineHandle = VK_NULL_HANDLE;
    pipeline_info.basePipelineIndex = -1;
    pipeline_info.layout = vk_ibl_comp_pipeline_layout->get();

    VkPipeline compute_pipeline;
    if (vkCreateComputePipelines(device_, VK_NULL_HANDLE, 1, &pipeline_info, nullptr, &compute_pipeline) != VK_SUCCESS) {
        throw std::runtime_error("failed to create compute pipeline!");
    }

    auto vk_pipeline = std::make_shared<VulkanPipeline>();
    vk_pipeline->set(compute_pipeline);

    return vk_pipeline;
}

std::shared_ptr<Swapchain> VulkanDevice::createSwapchain(
    std::shared_ptr<Surface> surface,
    uint32_t image_count,
    Format format,
    glm::uvec2 buf_size,
    ColorSpace color_space,
    SurfaceTransformFlagBits transform,
    PresentMode present_mode,
    std::vector<uint32_t> queue_index) {

    auto vk_surface = RENDER_TYPE_CAST(Surface, surface);

    VkSwapchainCreateInfoKHR create_info{};
    create_info.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR;
    create_info.surface = vk_surface->get();
    create_info.minImageCount = image_count;
    create_info.imageFormat = toVkFormat(format);
    create_info.imageColorSpace = toVkColorSpace(color_space);
    create_info.imageExtent = { buf_size.x, buf_size.y };
    create_info.imageArrayLayers = 1;
    create_info.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT; //VK_IMAGE_USAGE_TRANSFER_DST_BIT

    create_info.imageSharingMode = queue_index.size() > 1 ? VK_SHARING_MODE_CONCURRENT : VK_SHARING_MODE_EXCLUSIVE;
    create_info.queueFamilyIndexCount = static_cast<uint32_t>(queue_index.size() <= 1 ? 0 : queue_index.size());
    create_info.pQueueFamilyIndices = queue_index.size() <= 1 ? nullptr : queue_index.data();

    create_info.preTransform = toVkSurfaceTransformFlags(transform);
    create_info.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR;
    create_info.presentMode = toVkPresentMode(present_mode);
    create_info.clipped = VK_TRUE;
    create_info.oldSwapchain = VK_NULL_HANDLE; //need to be handled when resize.

    VkSwapchainKHR swap_chain;
    if (vkCreateSwapchainKHR(device_, &create_info, nullptr, &swap_chain) != VK_SUCCESS) {
        throw std::runtime_error("failed to create swap chain!");
    }

    auto vk_swap_chain = std::make_shared<VulkanSwapchain>();
    vk_swap_chain->set(swap_chain);
    return vk_swap_chain;
}

std::shared_ptr<Framebuffer> VulkanDevice::createFrameBuffer(
    const std::shared_ptr<RenderPass>& render_pass,
    const std::vector<std::shared_ptr<ImageView>>& attachments,
    const glm::uvec2& extent) {

    std::vector<VkImageView> image_views(attachments.size());
    for (int i = 0; i < attachments.size(); i++) {
        auto vk_image_view = RENDER_TYPE_CAST(ImageView, attachments[i]);
        image_views[i] = vk_image_view->get();
    }

    auto vk_render_pass = RENDER_TYPE_CAST(RenderPass, render_pass);
    VkFramebufferCreateInfo framebuffer_info{};
    framebuffer_info.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
    framebuffer_info.renderPass = vk_render_pass->get();
    framebuffer_info.attachmentCount = static_cast<uint32_t>(image_views.size());
    framebuffer_info.pAttachments = image_views.data();
    framebuffer_info.width = extent.x;
    framebuffer_info.height = extent.y;
    framebuffer_info.layers = 1;

    VkFramebuffer frame_buffer;
    if (vkCreateFramebuffer(device_, &framebuffer_info, nullptr, &frame_buffer) != VK_SUCCESS) {
        throw std::runtime_error("failed to create framebuffer!");
    }

    auto vk_frame_buffer = std::make_shared<VulkanFramebuffer>();
    vk_frame_buffer->set(frame_buffer);
    return vk_frame_buffer;
}

std::shared_ptr<DescriptorPool> VulkanDevice::createDescriptorPool() {
    VkDescriptorPoolSize pool_sizes[] =
    {
        { VK_DESCRIPTOR_TYPE_SAMPLER, 256 },
        { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 256 },
        { VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE, 256 },
        { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 256 },
        { VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER, 256 },
        { VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER, 256 },
        { VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, 256 },
        { VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, 256 },
        { VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC, 256 },
        { VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC, 256 },
        { VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, 256 }
    };
    VkDescriptorPoolCreateInfo pool_info = {};
    pool_info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
    pool_info.flags = VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT;
    pool_info.maxSets = 256 * IM_ARRAYSIZE(pool_sizes);
    pool_info.poolSizeCount = (uint32_t)IM_ARRAYSIZE(pool_sizes);
    pool_info.pPoolSizes = pool_sizes;
    VkDescriptorPool descriptor_pool;
    if (vkCreateDescriptorPool(device_, &pool_info, nullptr, &descriptor_pool) != VK_SUCCESS) {
        throw std::runtime_error("failed to create descriptor pool!");
    }

    auto vk_descriptor_pool = std::make_shared<VulkanDescriptorPool>();
    vk_descriptor_pool->set(descriptor_pool);
    return vk_descriptor_pool;
}

void VulkanDevice::updateDescriptorSets(
    const std::vector<TextureDescriptor>& texture_list,
    const std::vector<BufferDescriptor>& buffer_list) {

    std::vector<VkWriteDescriptorSet> descriptor_writes;
    std::vector<VkDescriptorImageInfo> desc_image_infos(texture_list.size());
    descriptor_writes.reserve(10);
    for (auto i = 0; i < texture_list.size(); i++) {
        const auto& tex = texture_list[i];
        auto vk_texture = RENDER_TYPE_CAST(ImageView, tex.texture);
        auto vk_sampler = RENDER_TYPE_CAST(Sampler, tex.sampler);
        auto vk_desc_set = RENDER_TYPE_CAST(DescriptorSet, tex.desc_set);
        desc_image_infos[i].imageLayout = toVkImageLayout(tex.image_layout);
        desc_image_infos[i].imageView = vk_texture->get();
        desc_image_infos[i].sampler = vk_sampler->get();
        descriptor_writes.push_back(
            addDescriptWrite(
                vk_desc_set->get(),
                desc_image_infos[i],
                tex.binding,
                toVkDescriptorType(tex.desc_type)));
    }

    std::vector<VkDescriptorBufferInfo> desc_buffer_infos(buffer_list.size());
    for (auto i = 0; i < buffer_list.size(); i++) {
        const auto& buf = buffer_list[i];
        auto vk_buffer = RENDER_TYPE_CAST(Buffer, buf.buffer);
        auto vk_desc_set = RENDER_TYPE_CAST(DescriptorSet, buf.desc_set);
        desc_buffer_infos[i].buffer = vk_buffer->get();
        desc_buffer_infos[i].offset = buf.offset;
        desc_buffer_infos[i].range = buf.range;

        VkWriteDescriptorSet descriptor_write = {};
        descriptor_write.sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
        descriptor_write.dstSet = vk_desc_set->get();
        descriptor_write.dstBinding = buf.binding;
        descriptor_write.dstArrayElement = 0;

        descriptor_write.descriptorType = toVkDescriptorType(buf.desc_type);
        descriptor_write.descriptorCount = 1;
        descriptor_write.pBufferInfo = &desc_buffer_infos[i];
        descriptor_writes.push_back(descriptor_write);
    }

    vkUpdateDescriptorSets(device_,
        static_cast<uint32_t>(descriptor_writes.size()),
        descriptor_writes.data(),
        0,
        nullptr);
}

void VulkanDevice::updateBufferMemory(
    const std::shared_ptr<DeviceMemory>& memory,
    uint64_t size,
    const void* src_data,
    uint64_t offset/* = 0*/) {
    if (memory) {
        void* dst_data = mapMemory(memory, size, offset);
        assert(dst_data);
        memcpy(dst_data, src_data, size);
        unmapMemory(memory);
    }
}

std::vector<std::shared_ptr<Image>> VulkanDevice::getSwapchainImages(std::shared_ptr<Swapchain> swap_chain) {
    auto vk_swap_chain = RENDER_TYPE_CAST(Swapchain, swap_chain);
    uint32_t image_count;
    std::vector<VkImage> swap_chain_images;
    vkGetSwapchainImagesKHR(device_, vk_swap_chain->get(), &image_count, nullptr);
    swap_chain_images.resize(image_count);
    vkGetSwapchainImagesKHR(device_, vk_swap_chain->get(), &image_count, swap_chain_images.data());

    std::vector<std::shared_ptr<Image>> vk_swap_chain_images(swap_chain_images.size());
    for (int i = 0; i < swap_chain_images.size(); i++) {
        auto vk_image = std::make_shared<VulkanImage>();
        vk_image->set(swap_chain_images[i]);
        vk_swap_chain_images[i] = vk_image;
    }
    return vk_swap_chain_images;
}

std::shared_ptr<DeviceMemory> VulkanDevice::allocateMemory(uint64_t buf_size, uint32_t memory_type_bits, MemoryPropertyFlags properties) {
    VkMemoryAllocateInfo alloc_info{};
    alloc_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
    alloc_info.allocationSize = buf_size;
    alloc_info.memoryTypeIndex = findMemoryType(getPhysicalDevice(), memory_type_bits, properties);

    VkDeviceMemory memory;
    if (vkAllocateMemory(device_, &alloc_info, nullptr, &memory) != VK_SUCCESS) {
        throw std::runtime_error("failed to allocate buffer memory!");
    }

    auto result = std::make_shared<VulkanDeviceMemory>();
    result->set(memory);

    return result;
}

MemoryRequirements VulkanDevice::getBufferMemoryRequirements(std::shared_ptr<Buffer> buffer) {
    auto vk_buffer = RENDER_TYPE_CAST(Buffer, buffer);

    MemoryRequirements mem_requirements = {};
    if (vk_buffer) {
        VkMemoryRequirements vk_mem_requirements;
        vkGetBufferMemoryRequirements(device_, vk_buffer->get(), &vk_mem_requirements);
        mem_requirements.size = vk_mem_requirements.size;
        mem_requirements.alignment = vk_mem_requirements.alignment;
        mem_requirements.memory_type_bits = vk_mem_requirements.memoryTypeBits;
    }

    return mem_requirements;
}

MemoryRequirements VulkanDevice::getImageMemoryRequirements(std::shared_ptr<Image> image) {
    auto vk_image = RENDER_TYPE_CAST(Image, image);

    MemoryRequirements mem_requirements = {};
    if (vk_image) {
        VkMemoryRequirements vk_mem_requirements;
        vkGetImageMemoryRequirements(device_, vk_image->get(), &vk_mem_requirements);
        mem_requirements.size = vk_mem_requirements.size;
        mem_requirements.alignment = vk_mem_requirements.alignment;
        mem_requirements.memory_type_bits = vk_mem_requirements.memoryTypeBits;
    }

    return mem_requirements;
}

void VulkanDevice::bindBufferMemory(std::shared_ptr<Buffer> buffer, std::shared_ptr<DeviceMemory> buffer_memory, uint64_t offset/* = 0*/) {
    auto vk_buffer = RENDER_TYPE_CAST(Buffer, buffer);
    auto vk_buffer_memory = RENDER_TYPE_CAST(DeviceMemory, buffer_memory);

    if (vk_buffer && vk_buffer_memory) {
        vkBindBufferMemory(device_, vk_buffer->get(), vk_buffer_memory->get(), offset);
    }
}

void VulkanDevice::bindImageMemory(std::shared_ptr<Image> image, std::shared_ptr<DeviceMemory> image_memory, uint64_t offset/* = 0*/) {
    auto vk_image = RENDER_TYPE_CAST(Image, image);
    auto vk_image_memory = RENDER_TYPE_CAST(DeviceMemory, image_memory);

    if (vk_image && vk_image_memory) {
        vkBindImageMemory(device_, vk_image->get(), vk_image_memory->get(), offset);
    }
}

std::vector<std::shared_ptr<CommandBuffer>> VulkanDevice::allocateCommandBuffers(std::shared_ptr<CommandPool> cmd_pool, uint32_t num_buffers, bool is_primary/* = true*/) {
    auto vk_cmd_pool = RENDER_TYPE_CAST(CommandPool, cmd_pool);
    std::vector<VkCommandBuffer> cmd_bufs(num_buffers);

    if (vk_cmd_pool) {
        VkCommandBufferAllocateInfo alloc_info{};
        alloc_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
        alloc_info.commandPool = vk_cmd_pool->get();
        alloc_info.level = is_primary ? VK_COMMAND_BUFFER_LEVEL_PRIMARY : VK_COMMAND_BUFFER_LEVEL_SECONDARY;
        alloc_info.commandBufferCount = num_buffers;

        if (vkAllocateCommandBuffers(device_, &alloc_info, cmd_bufs.data()) != VK_SUCCESS) {
            throw std::runtime_error("failed to allocate command buffers!");
        }
    }

    std::vector<std::shared_ptr<CommandBuffer>> result(num_buffers);
    for (uint32_t i = 0; i < num_buffers; i++) {
        auto cmd_buf = std::make_shared<VulkanCommandBuffer>();
        cmd_buf->set(cmd_bufs[i]);
        result[i] = cmd_buf;
    }

    return result;
}

void* VulkanDevice::mapMemory(std::shared_ptr<DeviceMemory> memory, uint64_t size, uint64_t offset /*=0*/) {
    void* data = nullptr;
    auto vk_memory = RENDER_TYPE_CAST(DeviceMemory, memory);
    if (vk_memory) {
        vkMapMemory(device_, vk_memory->get(), offset, size, 0/*reserved*/, &data);
    }

    return data;
}

void VulkanDevice::unmapMemory(std::shared_ptr<DeviceMemory> memory) {
    auto vk_memory = RENDER_TYPE_CAST(DeviceMemory, memory);
    if (vk_memory) {
        vkUnmapMemory(device_, vk_memory->get());
    }
}

void VulkanDevice::destroyCommandPool(std::shared_ptr<CommandPool> cmd_pool) {
    auto vk_cmd_pool = RENDER_TYPE_CAST(CommandPool, cmd_pool);
    if (vk_cmd_pool) {
        vkDestroyCommandPool(device_, vk_cmd_pool->get(), nullptr);
    }
}

void VulkanDevice::destroySwapchain(std::shared_ptr<Swapchain> swapchain) {
    auto vk_swapchain = RENDER_TYPE_CAST(Swapchain, swapchain);
    if (vk_swapchain) {
        vkDestroySwapchainKHR(device_, vk_swapchain->get(), nullptr);
    }
}

void VulkanDevice::destroyDescriptorPool(std::shared_ptr<DescriptorPool> descriptor_pool) {
    auto vk_descriptor_pool = RENDER_TYPE_CAST(DescriptorPool, descriptor_pool);
    if (vk_descriptor_pool) {
        vkDestroyDescriptorPool(device_, vk_descriptor_pool->get(), nullptr);
    }
}

void VulkanDevice::destroyPipeline(std::shared_ptr<Pipeline> pipeline) {
    auto vk_pipeline = RENDER_TYPE_CAST(Pipeline, pipeline);
    if (vk_pipeline) {
        vkDestroyPipeline(device_, vk_pipeline->get(), nullptr);
    }
}

void VulkanDevice::destroyPipelineLayout(std::shared_ptr<PipelineLayout> pipeline_layout) {
    auto vk_pipeline_layout = RENDER_TYPE_CAST(PipelineLayout, pipeline_layout);
    if (vk_pipeline_layout) {
        vkDestroyPipelineLayout(device_, vk_pipeline_layout->get(), nullptr);
    }
}

void VulkanDevice::destroyRenderPass(std::shared_ptr<RenderPass> render_pass) {
    auto vk_render_pass = RENDER_TYPE_CAST(RenderPass, render_pass);
    if (vk_render_pass) {
        vkDestroyRenderPass(device_, vk_render_pass->get(), nullptr);
    }
}

void VulkanDevice::destroyFramebuffer(std::shared_ptr<Framebuffer> frame_buffer) {
    auto vk_framebuffer = RENDER_TYPE_CAST(Framebuffer, frame_buffer);
    if (vk_framebuffer) {
        vkDestroyFramebuffer(device_, vk_framebuffer->get(), nullptr);
    }
}

void VulkanDevice::destroyImageView(std::shared_ptr<ImageView> image_view) {
    auto vk_image_view = RENDER_TYPE_CAST(ImageView, image_view);
    if (vk_image_view) {
        vkDestroyImageView(device_, vk_image_view->get(), nullptr);
    }
}

void VulkanDevice::destroySampler(std::shared_ptr<Sampler> sampler) {
    auto vk_sampler = RENDER_TYPE_CAST(Sampler, sampler);
    if (vk_sampler) {
        vkDestroySampler(device_, vk_sampler->get(), nullptr);
    }
}

void VulkanDevice::destroyImage(std::shared_ptr<Image> image) {
    auto vk_image = RENDER_TYPE_CAST(Image, image);
    if (vk_image) {
        vkDestroyImage(device_, vk_image->get(), nullptr);
    }
}

void VulkanDevice::destroyBuffer(std::shared_ptr<Buffer> buffer) {
    auto vk_buffer = RENDER_TYPE_CAST(Buffer, buffer);
    if (vk_buffer) {
        vkDestroyBuffer(device_, vk_buffer->get(), nullptr);
    }
}

void VulkanDevice::destroySemaphore(std::shared_ptr<Semaphore> semaphore) {
    auto vk_semaphore = RENDER_TYPE_CAST(Semaphore, semaphore);
    if (vk_semaphore) {
        vkDestroySemaphore(device_, vk_semaphore->get(), nullptr);
    }
}

void VulkanDevice::destroyFence(std::shared_ptr<Fence> fence) {
    auto vk_fence = RENDER_TYPE_CAST(Fence, fence);
    if (vk_fence) {
        vkDestroyFence(device_, vk_fence->get(), nullptr);
    }
}

void VulkanDevice::destroyDescriptorSetLayout(std::shared_ptr<DescriptorSetLayout> layout) {
    auto vk_layout = RENDER_TYPE_CAST(DescriptorSetLayout, layout);
    if (vk_layout) {
        vkDestroyDescriptorSetLayout(device_, vk_layout->get(), nullptr);
    }
}

void VulkanDevice::destroyShaderModule(std::shared_ptr<ShaderModule> shader_module) {
    auto vk_shader_module = RENDER_TYPE_CAST(ShaderModule, shader_module);
    if (vk_shader_module) {
        vkDestroyShaderModule(device_, vk_shader_module->get(), nullptr);
    }
}

void VulkanDevice::freeMemory(std::shared_ptr<DeviceMemory> memory) {
    auto vk_memory = RENDER_TYPE_CAST(DeviceMemory, memory);
    if (vk_memory) {
        vkFreeMemory(device_, vk_memory->get(), nullptr);
    }
}

void VulkanInstance::destroy() {
    if (enable_validation_layers) {
        DestroyDebugUtilsMessengerEXT(instance_, debug_messenger_, nullptr);
    }
    vkDestroyInstance(instance_, nullptr);
}

void VulkanDevice::freeCommandBuffers(std::shared_ptr<CommandPool> cmd_pool, const std::vector<std::shared_ptr<CommandBuffer>>& cmd_bufs) {
    auto vk_cmd_pool = RENDER_TYPE_CAST(CommandPool, cmd_pool);
    if (vk_cmd_pool) {
        std::vector<VkCommandBuffer> vk_cmd_bufs(cmd_bufs.size());
        for (uint32_t i = 0; i < cmd_bufs.size(); i++) {
            auto vk_cmd_buf = RENDER_TYPE_CAST(CommandBuffer, cmd_bufs[i]);
            vk_cmd_bufs[i] = vk_cmd_buf->get();
        }

        vkFreeCommandBuffers(device_, vk_cmd_pool->get(), static_cast<uint32_t>(vk_cmd_bufs.size()), vk_cmd_bufs.data());
    }
}

void VulkanDevice::resetFences(const std::vector<std::shared_ptr<Fence>>& fences) {
    std::vector<VkFence> vk_fences(fences.size());
    for (int i = 0; i < fences.size(); i++) {
        auto vk_fence = RENDER_TYPE_CAST(Fence, fences[i]);
        vk_fences[i] = vk_fence->get();
    }
    vkResetFences(device_, static_cast<uint32_t>(vk_fences.size()), vk_fences.data());
}

void VulkanDevice::waitForFences(const std::vector<std::shared_ptr<Fence>>& fences) {
    std::vector<VkFence> vk_fences(fences.size());
    for (int i = 0; i < fences.size(); i++) {
        auto vk_fence = RENDER_TYPE_CAST(Fence, fences[i]);
        vk_fences[i] = vk_fence->get();
    }
    vkWaitForFences(device_, static_cast<uint32_t>(vk_fences.size()), vk_fences.data(), VK_TRUE, UINT64_MAX);
}

void VulkanDevice::waitIdle() {
    vkDeviceWaitIdle(device_);
}

void VulkanQueue::submit(const std::vector<std::shared_ptr<CommandBuffer>>& command_buffers) {
    std::vector<VkCommandBuffer> vk_cmd_bufs(command_buffers.size());
    for (int i = 0; i < command_buffers.size(); i++) {
        auto vk_cmd_buf = RENDER_TYPE_CAST(CommandBuffer, command_buffers[i]);
        vk_cmd_bufs[i] = vk_cmd_buf->get();
    }

    VkSubmitInfo submit_info{};
    submit_info.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
    submit_info.commandBufferCount = static_cast<uint32_t>(command_buffers.size());
    submit_info.pCommandBuffers = vk_cmd_bufs.data();

    vkQueueSubmit(queue_, 1, &submit_info, VK_NULL_HANDLE);
}

void VulkanQueue::waitIdle() {
    vkQueueWaitIdle(queue_);
}

void VulkanCommandBuffer::beginCommandBuffer(CommandBufferUsageFlags flags) {
    VkCommandBufferBeginInfo begin_info{};
    begin_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
    begin_info.flags = toCommandBufferUsageFlags(flags);
    begin_info.pInheritanceInfo = nullptr; // Optional

    if (vkBeginCommandBuffer(cmd_buf_, &begin_info) != VK_SUCCESS) {
        throw std::runtime_error("failed to begin recording command buffer!");
    }
};

void VulkanCommandBuffer::endCommandBuffer() {
    if (vkEndCommandBuffer(cmd_buf_) != VK_SUCCESS) {
        throw std::runtime_error("failed to record command buffer!");
    }
}

void VulkanCommandBuffer::copyBuffer(
    std::shared_ptr<Buffer> src_buf,
    std::shared_ptr<Buffer> dst_buf,
    std::vector<BufferCopyInfo> copy_regions) {
    std::vector<VkBufferCopy> vk_copy_regions(copy_regions.size());
    for (uint32_t i = 0; i < copy_regions.size(); i++) {
        vk_copy_regions[i].srcOffset = copy_regions[i].src_offset;
        vk_copy_regions[i].dstOffset = copy_regions[i].dst_offset;
        vk_copy_regions[i].size = copy_regions[i].size;
    }
    auto vk_src_buf = RENDER_TYPE_CAST(Buffer, src_buf);
    auto vk_dst_buf = RENDER_TYPE_CAST(Buffer, dst_buf);
    vkCmdCopyBuffer(cmd_buf_, vk_src_buf->get(), vk_dst_buf->get(), static_cast<uint32_t>(vk_copy_regions.size()), vk_copy_regions.data());
}

void VulkanCommandBuffer::copyBufferToImage(
    std::shared_ptr<Buffer> src_buf,
    std::shared_ptr<Image> dst_image,
    std::vector<BufferImageCopyInfo> copy_regions,
    ImageLayout layout) {
    std::vector<VkBufferImageCopy> vk_copy_regions(copy_regions.size());
    for (uint32_t i = 0; i < copy_regions.size(); i++) {
        vk_copy_regions[i].bufferOffset = copy_regions[i].buffer_offset;
        vk_copy_regions[i].bufferRowLength = copy_regions[i].buffer_row_length;
        vk_copy_regions[i].bufferImageHeight = copy_regions[i].buffer_image_height;
        vk_copy_regions[i].imageSubresource.aspectMask = toVkImageAspectFlags(copy_regions[i].image_subresource.aspect_mask);
        vk_copy_regions[i].imageSubresource.mipLevel = copy_regions[i].image_subresource.mip_level;
        vk_copy_regions[i].imageSubresource.baseArrayLayer = copy_regions[i].image_subresource.base_array_layer;
        vk_copy_regions[i].imageSubresource.layerCount = copy_regions[i].image_subresource.layer_count;
        vk_copy_regions[i].imageOffset = { copy_regions[i].image_offset.x, copy_regions[i].image_offset.y, copy_regions[i].image_offset.z };
        vk_copy_regions[i].imageExtent = { copy_regions[i].image_extent.x, copy_regions[i].image_extent.y, copy_regions[i].image_extent.z };
    }
    auto vk_src_buf = RENDER_TYPE_CAST(Buffer, src_buf);
    auto vk_dst_image = RENDER_TYPE_CAST(Image, dst_image);
    vkCmdCopyBufferToImage(cmd_buf_, vk_src_buf->get(), vk_dst_image->get(), toVkImageLayout(layout), static_cast<uint32_t>(vk_copy_regions.size()), vk_copy_regions.data());
}

void VulkanCommandBuffer::bindPipeline(PipelineBindPoint bind, std::shared_ptr< Pipeline> pipeline) {
    auto vk_pipeline = RENDER_TYPE_CAST(Pipeline, pipeline);
    vkCmdBindPipeline(cmd_buf_, toVkPipelineBindPoint(bind), vk_pipeline->get());
}

void VulkanCommandBuffer::bindVertexBuffers(uint32_t first_bind, const std::vector<std::shared_ptr<Buffer>>& vertex_buffers, std::vector<uint64_t> offsets) {
    std::vector<VkDeviceSize> vk_offsets(vertex_buffers.size());
    std::vector<VkBuffer> vk_vertex_buffers(vertex_buffers.size());

    for (int i = 0; i < vertex_buffers.size(); i++) {
        auto vk_vertex_buffer = RENDER_TYPE_CAST(Buffer, vertex_buffers[i]);
        vk_vertex_buffers[i] = vk_vertex_buffer->get();
        vk_offsets[i] = i < offsets.size() ? offsets[i] : 0;
    }
    vkCmdBindVertexBuffers(cmd_buf_, first_bind, static_cast<uint32_t>(vk_vertex_buffers.size()), vk_vertex_buffers.data(), vk_offsets.data());
}

void VulkanCommandBuffer::bindIndexBuffer(std::shared_ptr<Buffer> index_buffer, uint64_t offset, IndexType index_type) {
    auto vk_index_buffer = RENDER_TYPE_CAST(Buffer, index_buffer);
    vkCmdBindIndexBuffer(cmd_buf_, vk_index_buffer->get(), offset, toVkIndexType(index_type));
}

void VulkanCommandBuffer::bindDescriptorSets(
    PipelineBindPoint bind_point,
    const std::shared_ptr<PipelineLayout>& pipeline_layout,
    const DescriptorSetList& desc_sets) {
    std::vector<VkDescriptorSet> vk_desc_sets;
    auto vk_pipeline_layout = RENDER_TYPE_CAST(PipelineLayout, pipeline_layout);
    for (auto i = 0; i < desc_sets.size(); i++) {
        vk_desc_sets.push_back(RENDER_TYPE_CAST(DescriptorSet, desc_sets[i])->get());
    }
    vkCmdBindDescriptorSets(
        cmd_buf_,
        toVkPipelineBindPoint(bind_point),
        vk_pipeline_layout->get(),
        0,
        static_cast<uint32_t>(vk_desc_sets.size()),
        vk_desc_sets.data(),
        0,
        nullptr);
}

void VulkanCommandBuffer::pushConstants(
    ShaderStageFlags stages,
    const std::shared_ptr<PipelineLayout>& pipeline_layout,
    const void* data,
    uint32_t size,
    uint32_t offset/* = 0*/) {
    auto vk_pipeline_layout = RENDER_TYPE_CAST(PipelineLayout, pipeline_layout);
    vkCmdPushConstants(
        cmd_buf_,
        vk_pipeline_layout->get(),
        toVkShaderStageFlags(stages),
        offset,
        size,
        data);
}

void VulkanCommandBuffer::draw(uint32_t vertex_count, uint32_t instance_count/* = 1*/, uint32_t first_vertex/* = 0*/, uint32_t first_instance/* = 0*/) {
    vkCmdDraw(cmd_buf_, vertex_count, instance_count, first_vertex, first_instance);
}

void VulkanCommandBuffer::drawIndexed(uint32_t index_count, uint32_t instance_count/* = 1*/, uint32_t first_index/* = 0*/, uint32_t vertex_offset/* = 0*/, uint32_t first_instance/* = 0*/) {
    vkCmdDrawIndexed(cmd_buf_, index_count, instance_count, first_index, vertex_offset, first_instance);
}

void VulkanCommandBuffer::dispatch(uint32_t group_count_x, uint32_t group_count_y, uint32_t group_count_z/* = 1*/) {
    vkCmdDispatch(cmd_buf_, group_count_x, group_count_y, group_count_z);
}

void VulkanCommandBuffer::beginRenderPass(
    std::shared_ptr<RenderPass> render_pass,
    std::shared_ptr<Framebuffer> frame_buffer,
    const glm::uvec2& extent,
    const std::vector<ClearValue>& clear_values) {
    std::vector<VkClearValue> vk_clear_values(clear_values.size());

    for (int i = 0; i < clear_values.size(); i++) {
        std::memcpy(&vk_clear_values[i].color, &clear_values[i].color, sizeof(VkClearValue));
    }

    auto vk_render_pass = RENDER_TYPE_CAST(RenderPass, render_pass);
    auto vk_frame_buffer = RENDER_TYPE_CAST(Framebuffer, frame_buffer);

    assert(vk_render_pass);
    assert(vk_frame_buffer);
    VkRenderPassBeginInfo render_pass_info{};
    render_pass_info.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
    render_pass_info.renderPass = vk_render_pass->get();
    render_pass_info.framebuffer = vk_frame_buffer->get();
    render_pass_info.renderArea.offset = { 0, 0 };
    render_pass_info.renderArea.extent = { extent.x, extent.y };
    render_pass_info.clearValueCount = static_cast<uint32_t>(vk_clear_values.size());
    render_pass_info.pClearValues = vk_clear_values.data();

    vkCmdBeginRenderPass(cmd_buf_, &render_pass_info, VK_SUBPASS_CONTENTS_INLINE);
}

void VulkanCommandBuffer::endRenderPass() {
    vkCmdEndRenderPass(cmd_buf_);
}

void VulkanCommandBuffer::reset(uint32_t flags) {
    vkResetCommandBuffer(cmd_buf_, flags);
}

void VulkanCommandBuffer::addImageBarrier(
    const std::shared_ptr<Image>& image,
    const ImageResourceInfo& src_info,
    const ImageResourceInfo& dst_info,
    uint32_t base_mip/* = 0*/,
    uint32_t mip_count/* = 1*/,
    uint32_t base_layer/* = 0*/,
    uint32_t layer_count/* = 1*/) {
    auto vk_image = RENDER_TYPE_CAST(Image, image);

    VkImageMemoryBarrier barrier{};
    barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
    barrier.oldLayout = toVkImageLayout(src_info.image_layout);
    barrier.newLayout = toVkImageLayout(dst_info.image_layout);
    barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
    barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
    barrier.image = vk_image->get();
    barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
    barrier.subresourceRange.baseMipLevel = base_mip;
    barrier.subresourceRange.levelCount = mip_count;
    barrier.subresourceRange.baseArrayLayer = base_layer;
    barrier.subresourceRange.layerCount = layer_count;
    barrier.srcAccessMask = toVkAccessFlags(src_info.access_flags);
    barrier.dstAccessMask = toVkAccessFlags(dst_info.access_flags);

    vkCmdPipelineBarrier(
        cmd_buf_,
        toVkPipelineStageFlags(src_info.stage_flags),
        toVkPipelineStageFlags(dst_info.stage_flags),
        0,
        0, nullptr,
        0, nullptr,
        1, &barrier
    );
}


ImageResourceInfo Helper::image_source_info_;
ImageResourceInfo Helper::image_as_color_attachement_;
ImageResourceInfo Helper::image_as_store_;
ImageResourceInfo Helper::image_as_shader_sampler_;
TextureInfo Helper::white_tex_;
TextureInfo Helper::black_tex_;

void Helper::init(const DeviceInfo& device_info) {
    create2x2Texture(device_info, 0xffffffff, white_tex_);
    create2x2Texture(device_info, 0xff000000, black_tex_);

    image_source_info_ = {
        ImageLayout::UNDEFINED,
        SET_FLAG_BIT(Access, SHADER_READ_BIT),
        SET_FLAG_BIT(PipelineStage, FRAGMENT_SHADER_BIT) };

    image_as_color_attachement_ = {
        ImageLayout::COLOR_ATTACHMENT_OPTIMAL,
        SET_FLAG_BIT(Access, COLOR_ATTACHMENT_WRITE_BIT),
        SET_FLAG_BIT(PipelineStage, COLOR_ATTACHMENT_OUTPUT_BIT) };

    image_as_store_ = {
        ImageLayout::GENERAL,
        SET_FLAG_BIT(Access, SHADER_WRITE_BIT),
        SET_FLAG_BIT(PipelineStage, COMPUTE_SHADER_BIT) };

    image_as_shader_sampler_ = {
        ImageLayout::SHADER_READ_ONLY_OPTIMAL,
        SET_FLAG_BIT(Access, SHADER_READ_BIT),
        SET_FLAG_BIT(PipelineStage, FRAGMENT_SHADER_BIT) |
        SET_FLAG_BIT(PipelineStage, COMPUTE_SHADER_BIT) };
}

void Helper::destroy(const std::shared_ptr<Device>& device) {
    black_tex_.destroy(device);
    white_tex_.destroy(device);
}

std::shared_ptr<Instance> Helper::createInstance() {
    return work::createInstance();
}

std::shared_ptr<Surface> Helper::createSurface(
    const std::shared_ptr<Instance>& instance,
    GLFWwindow* window) {
    return work::createSurface(instance, window);
}

PhysicalDeviceList Helper::collectPhysicalDevices(
    const std::shared_ptr<Instance>& instance) {
    return work::collectPhysicalDevices(instance);
}

std::shared_ptr<PhysicalDevice> Helper::pickPhysicalDevice(
    const PhysicalDeviceList& physical_devices,
    const std::shared_ptr<Surface>& surface) {
    return work::pickPhysicalDevice(physical_devices, surface);
}

QueueFamilyIndices Helper::findQueueFamilies(
    const std::shared_ptr<PhysicalDevice>& physical_device,
    const std::shared_ptr<Surface>& surface) {
    return work::findQueueFamilies(physical_device, surface);
}

std::shared_ptr<Device> Helper::createLogicalDevice(
    const std::shared_ptr<PhysicalDevice>& physical_device,
    const std::shared_ptr<Surface>& surface,
    const QueueFamilyIndices& indices) {
    return work::createLogicalDevice(physical_device, surface, indices);
}

void Helper::createSwapChain(
    GLFWwindow* window,
    const std::shared_ptr<Device>& device,
    const std::shared_ptr<Surface>& surface,
    const QueueFamilyIndices& indices,
    SwapChainInfo& swap_chain_info) {
    const auto& vk_device = RENDER_TYPE_CAST(Device, device);
    const auto& vk_physical_device = vk_device->getPhysicalDevice();
    SwapChainSupportDetails swap_chain_support = querySwapChainSupport(vk_physical_device, surface);

    VkSurfaceFormatKHR surface_format = chooseSwapSurfaceFormat(swap_chain_support.formats_);
    auto present_mode = chooseSwapPresentMode(swap_chain_support.present_modes_);
    VkExtent2D extent = chooseSwapExtent(window, swap_chain_support.capabilities_);

    uint32_t image_count = swap_chain_support.capabilities_.minImageCount + 1;
    if (swap_chain_support.capabilities_.maxImageCount > 0 && image_count > swap_chain_support.capabilities_.maxImageCount) {
        image_count = swap_chain_support.capabilities_.maxImageCount;
    }

    std::vector<uint32_t> queue_index(2);
    queue_index[0] = indices.graphics_family_.value();
    queue_index[1] = indices.present_family_.value();
    std::sort(queue_index.begin(), queue_index.end());
    auto last = std::unique(queue_index.begin(), queue_index.end());
    queue_index.erase(last, queue_index.end());

    swap_chain_info.format = fromVkFormat(surface_format.format);
    swap_chain_info.extent = glm::uvec2(extent.width, extent.height);

    swap_chain_info.swap_chain = device->createSwapchain(surface,
        image_count,
        swap_chain_info.format,
        swap_chain_info.extent,
        fromVkColorSpace(surface_format.colorSpace),
        fromVkSurfaceTransformFlags(swap_chain_support.capabilities_.currentTransform),
        present_mode,
        queue_index);

    swap_chain_info.images = device->getSwapchainImages(swap_chain_info.swap_chain);
}

Format Helper::findDepthFormat(const std::shared_ptr<Device>& device) {
    return work::findDepthFormat(device);
}

void Helper::addOneTexture(
    std::vector<TextureDescriptor>& descriptor_writes,
    uint32_t binding,
    const std::shared_ptr<Sampler>& sampler,
    const std::shared_ptr<ImageView>& texture,
    const std::shared_ptr<DescriptorSet>& desc_set,
    DescriptorType desc_type/* = DescriptorType::COMBINED_IMAGE_SAMPLER*/,
    ImageLayout image_layout/* = ImageLayout::SHADER_READ_ONLY_OPTIMAL*/) {

    TextureDescriptor tex_desc = {
        binding,
        sampler,
        texture,
        desc_set,
        desc_type,
        image_layout };

    descriptor_writes.push_back(tex_desc);
}

void Helper::addOneBuffer(
    std::vector<BufferDescriptor>& descriptor_writes,
    uint32_t binding,
    const std::shared_ptr<Buffer>& buffer,
    const std::shared_ptr<DescriptorSet>& desc_set,
    DescriptorType desc_type,
    uint32_t range,
    uint32_t offset/* = 0*/) {

    BufferDescriptor buffer_desc = {
        binding,
        offset,
        range,
        buffer,
        desc_set,
        desc_type };

    descriptor_writes.push_back(buffer_desc);
}

void Helper::createBufferWithSrcData(
    const DeviceInfo& device_info,
    const BufferUsageFlags& usage,
    const uint64_t& buffer_size,
    const void* src_data,
    std::shared_ptr<Buffer>& buffer,
    std::shared_ptr<DeviceMemory>& buffer_memory) {
    const auto& device = device_info.device;

    std::shared_ptr<Buffer> staging_buffer;
    std::shared_ptr<DeviceMemory> staging_buffer_memory;
    device->createBuffer(
        buffer_size,
        SET_FLAG_BIT(BufferUsage, TRANSFER_SRC_BIT),
        SET_FLAG_BIT(MemoryProperty, HOST_VISIBLE_BIT) |
        SET_FLAG_BIT(MemoryProperty, HOST_COHERENT_BIT),
        staging_buffer,
        staging_buffer_memory);

    device->updateBufferMemory(staging_buffer_memory, buffer_size, src_data);

    device->createBuffer(
        buffer_size,
        SET_FLAG_BIT(BufferUsage, TRANSFER_DST_BIT) | usage,
        SET_FLAG_BIT(MemoryProperty, DEVICE_LOCAL_BIT),
        buffer,
        buffer_memory);

    copyBuffer(device_info, staging_buffer, buffer, buffer_size);

    device->destroyBuffer(staging_buffer);
    device->freeMemory(staging_buffer_memory);
}

void Helper::generateMipmapLevels(
    const std::shared_ptr<CommandBuffer>& cmd_buf,
    const std::shared_ptr<Image>& image,
    uint32_t mip_count,
    uint32_t width,
    uint32_t height,
    const ImageLayout& cur_image_layout) {
    work::generateMipmapLevels(cmd_buf, image, mip_count, width, height, cur_image_layout);
}

void Helper::create2DTextureImage(
    const DeviceInfo& device_info,
    Format format,
    int tex_width,
    int tex_height,
    int tex_channels,
    const void* pixels,
    std::shared_ptr<Image>& texture_image,
    std::shared_ptr<DeviceMemory>& texture_image_memory) {

    const auto& device = device_info.device;
    VkDeviceSize image_size = static_cast<VkDeviceSize>(tex_width * tex_height * 4);

    std::shared_ptr<Buffer> staging_buffer;
    std::shared_ptr<DeviceMemory> staging_buffer_memory;
    device->createBuffer(
        image_size,
        SET_FLAG_BIT(BufferUsage, TRANSFER_SRC_BIT),
        SET_FLAG_BIT(MemoryProperty, HOST_VISIBLE_BIT) |
        SET_FLAG_BIT(MemoryProperty, HOST_COHERENT_BIT),
        staging_buffer,
        staging_buffer_memory);

    device->updateBufferMemory(staging_buffer_memory, image_size, pixels);

    create2DImage(
        device,
        glm::vec2(tex_width, tex_height),
        format,
        ImageTiling::OPTIMAL,
        SET_FLAG_BIT(ImageUsage, TRANSFER_DST_BIT) |
        SET_FLAG_BIT(ImageUsage, SAMPLED_BIT),
        SET_FLAG_BIT(MemoryProperty, DEVICE_LOCAL_BIT),
        texture_image,
        texture_image_memory);

    transitionImageLayout(device_info, texture_image, format, ImageLayout::UNDEFINED, ImageLayout::TRANSFER_DST_OPTIMAL);
    copyBufferToImage(device_info, staging_buffer, texture_image, glm::uvec2(tex_width, tex_height));
    transitionImageLayout(device_info, texture_image, format, ImageLayout::TRANSFER_DST_OPTIMAL, ImageLayout::SHADER_READ_ONLY_OPTIMAL);

    device->destroyBuffer(staging_buffer);
    device->freeMemory(staging_buffer_memory);
}

void Helper::createDepthResources(
    const DeviceInfo& device_info,
    Format depth_format,
    glm::uvec2 size,
    TextureInfo& depth_buffer) {
    const auto& device = device_info.device;
    create2DImage(
        device,
        size,
        depth_format,
        ImageTiling::OPTIMAL,
        SET_FLAG_BIT(ImageUsage, DEPTH_STENCIL_ATTACHMENT_BIT),
        SET_FLAG_BIT(MemoryProperty, DEVICE_LOCAL_BIT),
        depth_buffer.image,
        depth_buffer.memory);

    depth_buffer.view =
        device->createImageView(
            depth_buffer.image,
            ImageViewType::VIEW_2D,
            depth_format,
            SET_FLAG_BIT(ImageAspect, DEPTH_BIT));

    transitionImageLayout(
        device_info,
        depth_buffer.image,
        depth_format,
        ImageLayout::UNDEFINED,
        ImageLayout::DEPTH_STENCIL_ATTACHMENT_OPTIMAL);
}

void Helper::createCubemapTexture(
    const DeviceInfo& device_info,
    const std::shared_ptr<RenderPass>& render_pass,
    uint32_t width,
    uint32_t height,
    uint32_t mip_count,
    Format format,
    const std::vector<BufferImageCopyInfo>& copy_regions,
    TextureInfo& texture,
    uint64_t buffer_size /*= 0*/,
    void* data /*= nullptr*/)
{
    const auto& device = device_info.device;
    bool use_as_framebuffer = data == nullptr;
    VkDeviceSize image_size = static_cast<VkDeviceSize>(buffer_size);

    std::shared_ptr<Buffer> staging_buffer;
    std::shared_ptr<DeviceMemory> staging_buffer_memory;
    if (data) {
        device->createBuffer(
            image_size,
            SET_FLAG_BIT(BufferUsage, TRANSFER_SRC_BIT),
            SET_FLAG_BIT(MemoryProperty, HOST_VISIBLE_BIT) |
            SET_FLAG_BIT(MemoryProperty, HOST_COHERENT_BIT),
            staging_buffer,
            staging_buffer_memory);

        device->updateBufferMemory(staging_buffer_memory, buffer_size, data);
    }

    auto image_usage_flags =
        SET_FLAG_BIT(ImageUsage, TRANSFER_DST_BIT) |
        SET_FLAG_BIT(ImageUsage, SAMPLED_BIT) |
        SET_FLAG_BIT(ImageUsage, STORAGE_BIT);

    if (use_as_framebuffer) {
        image_usage_flags |=
            SET_FLAG_BIT(ImageUsage, COLOR_ATTACHMENT_BIT) |
            SET_FLAG_BIT(ImageUsage, TRANSFER_SRC_BIT);
    }

    texture.image = device->createImage(
        ImageType::TYPE_2D,
        glm::uvec3(width, height, 1),
        format,
        image_usage_flags,
        ImageTiling::OPTIMAL,
        ImageLayout::UNDEFINED,
        SET_FLAG_BIT(ImageCreate, CUBE_COMPATIBLE_BIT),
        false,
        1,
        mip_count,
        6u);

    auto mem_requirements = device->getImageMemoryRequirements(texture.image);
    texture.memory = device->allocateMemory(
        mem_requirements.size,
        mem_requirements.memory_type_bits,
        toVkMemoryPropertyFlags(SET_FLAG_BIT(MemoryProperty, DEVICE_LOCAL_BIT)));
    device->bindImageMemory(texture.image, texture.memory);

    if (data) {
        transitionImageLayout(device_info, texture.image, format, ImageLayout::UNDEFINED, ImageLayout::TRANSFER_DST_OPTIMAL, 0, mip_count, 0, 6);
        copyBufferToImageWithMips(device_info, staging_buffer, texture.image, copy_regions);
        transitionImageLayout(device_info, texture.image, format, ImageLayout::TRANSFER_DST_OPTIMAL, ImageLayout::SHADER_READ_ONLY_OPTIMAL, 0, mip_count, 0, 6);
    }

    texture.view = device->createImageView(
        texture.image,
        ImageViewType::VIEW_CUBE,
        format,
        SET_FLAG_BIT(ImageAspect, COLOR_BIT),
        0,
        mip_count,
        0,
        6);

    assert(render_pass);

    if (use_as_framebuffer) {
        texture.surface_views.resize(mip_count);
        texture.framebuffers.resize(mip_count);
        auto w = width;
        auto h = height;

        for (uint32_t i = 0; i < mip_count; ++i)
        {
            texture.surface_views[i].resize(6, VK_NULL_HANDLE); //sides of the cube

            for (uint32_t j = 0; j < 6; j++)
            {
                texture.surface_views[i][j] =
                    device->createImageView(
                        texture.image,
                        ImageViewType::VIEW_2D,
                        format,
                        SET_FLAG_BIT(ImageAspect, COLOR_BIT),
                        i,
                        1,
                        j,
                        1);
            }

            texture.framebuffers[i] = device->createFrameBuffer(render_pass, texture.surface_views[i], glm::uvec2(w, h));
            w = std::max(w >> 1, 1u);
            h = std::max(h >> 1, 1u);
        }
    }

    if (data) {
        device->destroyBuffer(staging_buffer);
        device->freeMemory(staging_buffer_memory);
    }
}

} // renderer
} // work